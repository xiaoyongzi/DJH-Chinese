:chapnum: 04
:figure-number: 00

[[getting_data]]
== 获取数据 ==

image::figs/incoming/04-00-cover.png[float="none",role="informal"]

++++
<?dbfo-need height="1in"?>
++++

那么，你已经准备开始第一个数据新闻项目。下一步呢？首先，你需要一些数据。这章节讨论从何处获得数据。我们将会学习到如何在网上找到数据，如何运用信息自由法律向有关方面请求数据，如何使用“截屏”从非结构化的来源搜集数据以及如何使用“众包”从你的读者收集数据集。最后是哪些法律如何规定重新发布数据集，以及如何使用简单的法律工具确保别人也能够重复使用你的数据。 

=== 5分钟的学科指南

寻找关于一个特定的主题或问题的数据？不确定有什么数据或在哪儿找到这些数据？不知道如何入手？在这一小节我们来看看如何在网上寻找公共数据资源。

==== 精细你的搜索关键词

尽管这些数据常常不容易找到，但是实际上很多数据库都已经被搜索引擎所收录，不论这是否出于发布者的本意。这里有几点建议：

  * 当你搜索数据时，一定要包括与你所要寻找的数据内容相关的搜索术语，以及你所希望的格式或来源的信息。谷歌和其他搜索引擎都允许你通过文件类型搜索。例如，你可以只搜寻电子表格(通过添加您搜索的文件类型："filetype:XLS filetype:CSV")，地理数据("filetype:shp")，或数据库提取("filetype:MDB，filetype:SQL, filetype:DB")。可能的话，你甚至可以查找PDF格式的（‘文件类型：pdf’）
  * 您也可以通过搜索URL的一部分。Google的"inurl:downloads filetype:xls"功能能帮你找到所有的已经``下载''到在他们网络服务器上Excel文件（如果你已经找到了单个下载文件，这个搜索关键词往往能帮你在服务器上同一文件夹中的找到其他结果）。你还可以限制只在某一个单一的域名中的结果，比如通过搜索"site:agency.gov"。
  * 另一个经常使用的诀窍是，不直接搜索内容，而是搜索可提供批量数据的位置。例如，"site:agency.gov Directory Listing"可以给你一些由服务器生成的容易获得的源文件的列表，如果用"site:agency.gov Database Download"的话就会为你搜寻人工创建的列表。

++++
<?dbfo-need height="2in"?>
++++

.直接寻找源文件
****
要说如何拿到公共数据，我的第一个绝招就是尝试直奔数据持有者，不是公众人物，也不是通过信息自由申请。我当然能精心制作一份通过信息自由法案的申请或者公开记录的请求，但是效率会很慢。很可能我就会得到回应说数据跟我申请的格式不一样，或者（像有些案例里那样）政府部门会使用专有软件，无法按我请求的数据格式那样提取出来。但是，如果我一来就成功联系上持有某组织数据的人，我就可以直接问他关于某主题都有什么数据和存储方式。再者，我熟悉数据语言，知道如何成功地请求获取数据。你要问这种途径的障碍？障碍时有发生，你很难联系上这些人。公开信息官员(PIO) 会想让我去跟他们谈。我发现在有的案例中，最好的方式是发起一个会议请求，当然如果能和公开信息官员，数据高手一起私下会面就再好不过了。我也能用一种让他们很难拒绝的方式来请求。``我不想给他们增麻烦，''我说。``我不想给他们增添不必要的负担或者漫无边际的请求，所以一次会面能让我确切地了解他们有什么，以及对我能最顺利准确请求到数据所必须知道的那些。''

如果这种方法不奏效，我的备案是在请求中首先就问他们数据记录的结构和数据字典。下一步我才真正的去申请数据本身。我有时也会问他们如何存放数据，存在什么系统里。通过这种方式我就可以研究这些数据都能用哪些方法导出，这对申请来说非常有好处。

最后要说的是，我最成功的一次经历来在当我还为蒙特纳的一家小报工作的时候。我需要一些统计数据，但是我被告知我想要的数据没法从主机中导出来。我当时研究了一番，然后主动请缨去帮助他们一起解决数据导出的问题。我和管数据的人一同，写了一些简短的代码，最终把数据打印到了软盘里（那是很久以前的事了）。我得到了我的数据，并且我们开发的这个统计小工具也被他们所配备，就能给请求数据的人提供数据了。他们没料想到这样的事会发生，但是有时他们自己也需要提取一些数据。他们完全不了解他们的系统，所以我们互相帮助。

&mdash; _谢丽尔·菲利普斯(Cheryl Philips)，西雅图时报_
****

==== 浏览数据网站和服务

近几年在网络上涌现出大量专门的数据门户网站、数据中心和其他数据网站，在这里你可以找到各种公开的数据。如果你是个新手，可以先去看看这些资源：

[[FIG042]]
.datacatalogs.org（开放知识基金会）
image::figs/incoming/04-01.png[float="0"]

官方数据门户::
  政府发布数据的意愿在国家之间差别很大。越来越多的国家都开设了数据门户网站（受美国的data.gov以及英国的data.gov.uk所启发）去促进民众或企业对政府数据的再利用。在http://datacatalogs.org/[datacatalogs.org]这个网站上，你可以找到这些数据门户网站最新的索引信息。。另一个有用的网站是http://www.guardian.co.uk/world-government-data[卫报世界政府数据]，这是一个元数据搜索引擎，囊括了许多国家的政府数据条目。

http://thedatahub.org/[The Data Hub]::
  一个由开放知识基金会运作的以社区推动型(community-driven)数据资源，这让寻找、分享、再利用这些开放数据变的非常简单，特别是以机器自动化的方式来进行数据操作。

https://scraperwiki.com/[ScraperWiki]::
  一个在线工具，其目的是“简化有用数据的提取，使这些数据便于应用到其他应用程序，或者提供给记者和研究人员”。大多数的数据提取网站及其数据库都是公开的，可以重复使用。

http://data.worldbank.org/[世界银行] 和http://data.un.org/[联合国] 数据门户网站::
  世界银行和联合国的数据门户网站：为所有国家提供高水平的指标参数，数据通常可以追溯到多年以前。

http://buzzdata.com/[Buzzdata],http://www.infochimps.com/[Infochimps], 和http://datamarket.com/[DataMarket]::
  一些旨在建立社区数据分享和转售的新兴公司。

http://datacouch.com/[DataCouch]::
  一个能上传、完善、分享及数据可视化的网站。

http://www.freebase.com/[Freebase]::
  Freebase是谷歌旗下的一个很有意思的子公司，“由一帮热爱开放数据的团体开发，提供人、地址以及物体的实体图”。

研究数据::
  许多国家和学科都会对科研数据进行汇总，如http://www.data-archive.ac.uk/[英国数据档案]。其中有大量的数据可以免费访问，但也有不少是需要订阅，或需要管理机构同意才可使用和分发。

.从纸质文档中获取数据
****
正是在维基解密发布美国军方在阿富汗和伊拉克战争文档之后，我们决定遵循着这种概念，发布阿尔及利亚战争日记以纪念阿尔及利亚战争五十周年。我们开始去搜集并数字化法军在阿尔及利亚战争中的档案。这些可以在巴黎战争档案部都可以拿到，尽管都是纸质的。我们把这些档案分发给记者和学生，让他们把这些纸质档案拍成照片。我们也曾尝试过用佳能P-150便携扫描仪把他们扫描下来，但效果不是很好，主要因为这些档案都被装订过了。

最后，在几周之内收集到了大概有一万页的档案。我们试过用文字识别软件(ABBYY FineReader)去识别这些图片，但是结果不尽人意。还有就是，战争档案部门断然拒绝向我们提供另外几箱最有价值的档案。最重要的是，战争档案部禁止任何人再出版那些能被随意拍照关于地点的文档，所以我们决定不去冒这个风险，这个项目也就被搁置了。

&mdash; _尼古拉斯·凯瑟－布瑞尔（Nicolas Kayser-Bril），Journalism++_
****

==== 在论坛上发问

在http://getthedata.org/[Get The Data]或http://www.quora.com/[Quora]上搜索现成的答案或者提出问题。GetTheData是一个问答网站，你可以在上面问数据相关的问题，包括在哪里可以找到有关某一具体问题的数据、如何查询或检索某个特定的数据源、使用什么工具对数据进行可视化探索、如何净化数据或是如何转变成你可以使用的格式。

==== 在邮件列表中发问

邮件列表是整个团体在某个特定主题上的的智慧结晶。对于数据记者而言，http:/bit.ly/ddj-list[数据驱动新闻列表](Data Driven Journalism List)和http://bit.ly/nicar-subscribe/[NICAR-L]列表都是非常好的例子，不妨从它们开始。这些邮件列表上长期驻扎着从事各种项目的数据记者和计算机辅助报告 （CAR, Computer Assisted Reporting） 的极客。很可能其中有人做过跟你类似的项目，他即使不知道数据本身的链接，也可能有从何入手的想法。你也可以试试http://project-wombat.org[Wombat项目]（``一个针对引用困难问题的讨论列表''）http://lists.okfn.org/mailman/listinfo[开放知识基金会的许多邮件列表]、http://theinfo.org/[theInfo]上的邮件列表，或寻找关于你所感兴趣的主题或领域的邮件列表。

==== 加入黑客/骇客(Hacks/Hackers)

http://hackshackers.com/[Hacks/Hackers]是一个在迅速扩张的国际草根新闻组织，在四大洲有着数十个分会和成千上万的成员。其任务是建立一个重新思考新闻和信息的未来的记者("hacks")和技术专家("hackers")的网络。在这样一个广泛的网络中，很有可能有人知道去哪里搜索你所要的数据。

==== 请教专家

教授、公务员和业界人士通常知道到哪里查找数据。给他们打电话、发电子邮件、找机会跟他们搭讪、拜访他们的办公室。然后彬彬有礼的询问：``我正在做一个关于 X 的报道。我在哪儿能找到相关数据吗？你知道谁有这方面的信息吗？''

==== 了解政府信息技术

了解各国政府在维护信息中所使用的技术和管理体系，这在访问数据时常常会很有帮助。不论是CORDIS（欧盟研究与发展计划相关资料库）、COINS或THOMAS，一旦你了解到一些关于这些缩略词所代表的大型数据库的预期目标，它们经常会成为你最有用的资料来源。

查找政府组织结构图，找出具有交叉职能（如报告、IT服务部门）的部门或单位，然后浏览他们的网站。很多数据保存在多个部门，可能在一个部门视作掌上明珠的某个数据库，在另一个部门就是免费的午餐。

在政府网站上寻找动态信息图表。这些图表通常是由可独立使用的结构化的数据源或应用程序编程接口所支持的（例如，飞行跟踪程序和天气预报的java应用程序）。

.用电话记录来“钓鱼”
****
几个月之前，我想去剖析时任总统候选人所在的得克萨斯州政府。具体来说，我想要瑞克佩里(Rick Perry)的手机通话记录。那是我们已经期待已久的国家公开记录的申请结果。拿到手的数据是120页以上只有传真质量的档案。我们颇费了一番功夫进行数据录入和清理，再通过WhitePages.com的API去反向查询电话号码。

++++
<?dbfo-need height="1in"?>
++++

将这些人名与州和联邦政府(FEC)选举数据对应起来以后，我们发现佩里通过http://bo.st/perry-phone[州政府工作电话]伸手拿到了大量的选举经费和超级政治行动委员会(PAC, Political Action Committee)资助，这种令人不悦的做法掀起了对他和他所倾心的``超级政治行动委员会''之间勾连的质疑。

&mdash; _杰克·吉勒姆(Jack Gillum)，美联社_
****

==== 重复尝试搜索

当你知道更多数据相关的信息后，用你上次搜索所注意到的重要关键词组再搜索一次。这样你没准就走运搜到了你想要的数据！

==== 撰写一个信息自由请求

如果你认为政府机构握有你所需要的数据，写一个信息自由（Freedom of Information）请求书可能是最好的办法。有关如何撰写文件更多信息请参阅下一章节。

&mdash; _布赖恩·博耶（芝加哥论坛报），约翰·基夫（美国纽约公共广播公司），弗里德瑞克·林登伯格（开放知识基金会），简·帕克（Creative Commons）, 克里斯·吴（Hacks/Hackers）_

.当法律失效
****
我阅读过一篇学术文章 http://bit.ly/hygiene-inspections[scholarly article] 解释说公布洛杉矶的餐馆卫生状况检查结果可减少食品相关的病例, 于是我要求巴黎卫生系统提供其检查清单。据法国自由信息条例规定的程序，我等了三十天才收到了他们拒绝的答复，随后我转到可以裁决信息公开有效性的公众数据公开委员会(CADA法文)。 CADA支持我的请求，命令行政系统发布数据。行政部门于是要求两个月的宽限期，并获得CADA同意。两个月后，行政系统仍然无动于衷。

我试图通过一些支持数据公开的公众人物（以及有钱人）打官司（这是5千欧元的官司，有CADA撑腰包赚不输），可惜他们担心损害了他们与官方数据项目的关系。这只是众多案例中之一，但可看出法国政府部门完全罔顾法律，官方无意支持基层民众对于数据的需求。 

&mdash; _Nicolas Kayser-Bril, 记者++_
****

++++
<?dbfo-need height="2in"?>
++++

=== 你对数据的权利

在发出信息自由 (FOI) 申请之前，你应该查一下正在搜索的数据是否已经公开，或者是否已经有人提出过申请。你可以从上一章查阅其中的几个建议。如果你已经找了一圈还是没有得到所需要的数据，你可能就想要提交一份正式的申请。这里有一些提示，可以让你的申请更为有效。

提前计划 节省时间::
  每当你在搜索信息的时候，就要考虑提交一份正式的访问请求。最好不要等到用尽其他办法再作打算。在研究开始之时提交请求，同时开展其他调研，这样会为你节省时间。对拖延有所准备：公共机构有时需要一段时间来处理请求，所以你最好是对这一情况有所预期。

查看收费规定::
  在开始提交申请之前，查一下有关提交申请或接收信息的收费规定。这样一来，如果政府官员突然问你要钱，你会对自己的权利心里有数。你可以索要电子文档来避免拷贝和粘贴的成本，所以在申请中要写清楚你更希望获得电子格式的信息。这样就可以避免支付费用，除非是信息没有电子文档。不过现今通常可以将没有数字化的文件扫描，而后以电子邮件的附件的形式发送。

知晓你的权利::
  在开始之前搞清楚自己的权利，这样你就知道自己拥有何种权利以及公共部门的义务所在。例如，大部分信息自由法对当局的回复有一个时间限制。在全世界大多数法律中，该范围从几天到一个月不等。在你申请之前确定这一期限，并在提交申请时作好记录。

政府没有为你处理数据的义务，但应当向你提供他们所有的资料。如果根据政府所履行的法律能力应当提供某个数据，那么他们肯定应当为你制作。

声明你知道自己的权利::
  通常法律并没有要求你提及访问信息法或者信息自由法案，但建议你这样做，因为它表明你知道自己的合法权利，并且可能鼓励依法正确处理申请。我们注意到对于欧盟的申请，其中重要的一点是写明这是一个文件访问申请，而且最好具体写明是提案1049 /2001。

保持简洁::
  不论在哪个国家，最好都从一个简单的信息申请开始，如果得到了初步信息，然后再增加更多的问题。这样，你就不会因为提出一个``复杂的请求''而冒被公共机构申请延期的风险。

保证重点::
  申请由公共部门的一部分保有的信息，可能会比需要搜索整个部门的回复来得更快。需要官方咨询第三方（例如提供信息的私营公司、受其影响的其他政府）的申请可能会花费特别长的时间。你要持之以恒。

考虑文件所包含的信息::
  试着找出所整理的数据。举个例子，假如你在交通事故后拿到一张警察填写的表单空白副本，你就可以看出他们记录了哪些有关车祸的信息。

针对具体问题::
  在你提交申请之前，想想：它有什么含糊不清的地方吗？如果你计划比较来自不同官方部门的数据，这一点尤其重要。打个比方，如果你索要过去三年的数字，一些部门会发给你过去三个日历年的信息，而其它部门则发给你过去三个财政年的信息，你不可能直接比较这些信息。如果你决定要把你真正的申请隐藏在一个更普遍的申请当中，那么你的申请范围应当足以获取你想要的信息，但也能太过泛泛而用意不明或有碍回复。具体而明确的申请往往能够获得更快更好的答案。

提交多个申请::
  如果你不确定向谁提交申请，你完全可以在同一时间向两三个或更多的机构提交申请。在某些情况下，各机构会返回不同的答案，但这实际上是有帮助的，可以为你所调查的项目上提供更全面的信息。

提交国际申请::
  越来越多的申请可以以电子方式提交，所以你住在哪里并不重要。或者，如果你没有生活想要提交申请的国家中，有时可以将申请发送到大使馆，而他们应将其转移给公共机构。你需要先查看相关使馆是否有这类服务，有时使馆工作人员没有接受过对信息权利的培训，如果看似是这种情况，直接向有关公共机构提交申请是更安全的做法。

进行申请测试::
  如果在你打算给许多公共当局发送同一申请，开始的时候可以给几个部门发一份初步的申请草案作为提前测试。这会告诉你是否使用了正确的术语来获取想要的材料，以及回复你问题的可行性，这样你就可以在发送给各个部门之前对申请进行必要的修改。

考虑好意外情况::
  如果觉得你的申请可能会出现意外，那么在准备申请之时，你可以把可能存在敏感信息的问题与其它根据常识不会出现意外的信息分开。然后把你的问题分成两项申请并分别提交。

请求对文件的访问::
  如果你住在保存信息的机构附近（例如在存放文件的首都），你也可以要求查看文件的正本。当研究信息可能保存在大量的你想查阅的文献中时，这会是非常有用的。这类查阅应当是免收费用的，而且可以给你安排在一个合理和方便的时间。

自己留一份记录！:: 
  以书面形式作出申请，并保存一份副本或记录，以便在将来如果未收到答复需要作出上诉时，能够证明你的申请已经发送。并且假如你打算做一个有关报道，这也可以提供了申请提交的证据。

公开你的申请::
  通过把你提交的申请公开化可以加速回复的速度：如果你撰写或广播一个关于你已提交申请的报道，这可以对公共机构施加压力使其处理和回复你的申请。在收到对申请的回复后，你可以更新信息；如果超过截止时间仍没有回复，你也可以把这做为一个新闻报道。这样做还有一个好处，就是教育大众有关信息的访问权以及如何实践。


[NOTE]
====
在网上有几个公开的优质的服务机构，你可以用来提交申请以及任何后续的回复，如英国公共机构的http://www.whatdotheyknow.com/[What Do They Know?]、德国公共机构的https://fragdenstaat.de/[Frag den Staat]和欧盟机构的http://www.asktheeu.org/[Ask the EU]。而http://www.alaveteli.org/[Alaveteli]项目正在帮助世界各地的数十个国家开展类似的服务。
====

[[FIG043]]
.What Do They Know? (My Society)
image::figs/incoming/04-AA.png[float="none"]

发展你的同事::
  如果你的同事对信息申请访问的意义持怀疑态度，说服他们的最佳途径之一就是根据信息法所访问到信息写一篇报道。在最后一篇文章或广播片段中也把你所用到的法律推荐给公众，作为一种强调其价值并提高公众的权利意识的方法。

索要原始数据::
  如果你想要用电脑分析、挖掘或整理数据，那么你应当明确索要电子化的机器可读的数据格式。你可以通过详细说明来阐明你的要求，例如你需要``适用于会计软件分析''格式的预算信息。你可能还希望明确索要非汇总过的或松散表格的信息。关于这一点，你可以扩展阅读http://bit.ly/access-report[此报告]。

++++
<?dbfo-need height="1in"?>
++++

询问FOI法律之外的组织::
  你可能希望找到有关非政府组织、私营公司、宗教组织和其他组织中在FOI法律下并不需要公开的文件。但是通过询问FOI法律所涵盖的公共机构你可能找到有关的信息。例如，你可以询问政府部门或部委是否资助过或处理过某个特定私人公司或非政府组织，并申请支持文件。如果在 进行FOI申请需要进一步帮助，你还可以查阅 http://www.legalleaks.info/toolkit.html[记者所应该知道的法律漏洞](Legal Leaks tookit for journalists)。

&mdash; _海伦·达比希尔（Access Info Europe）、Djordje·Padejski（斯坦福大学奈特新闻会员）、马丁·罗森鲍姆（英国广播公司）和法布里齐奥·斯科诺利尼（伦敦政治经济学院）_

.利用“信息自由”了解公共支出
[[foi-spending]]
****
我曾经用不少方式应用FOI，以更好的了解COINS，它是最大的英国政府开支、预算、财政信息数据库。在2010年开始的时候，乔治·奥斯本透露他如果当选财政大臣，就会开放COINS，以促进财政部的信息公开透明。这看起来是个研究COINS中的各项数据的好时机，我便递出了几个FOI申请，一个是 http://bit.ly/wdtk-coins-1[数据库的架构]，一个是财政部官员在 http://bit.ly/wdtk-coins-2[使用COINS时的指南]，一个是财政部和数据库提供者之间 http://bit.ly/wdtk-coins-3[签订的合同]。这些都最终被以实用信息而 http://bit.ly/wdtk-coins-4[被公开]了。我还申请了公开所有的开支项目代码，也被公开了。乔治·奥斯本当2010年5月当选财政大臣，并于6月公开了COINS，而前面这些工作，都让我们对COINS有了更好的了解。数据库中的数据被多个网站应用，并鼓励公众自行研究这些数据，包括 http://openspending.org/[OpenSpending.org] 和《卫报》的 http://coins.guardian.co.uk/coins-explorer/search[Coins Data Explorer]。

After further investigation it seemed that a large part of the database was missing: the Whole of Government Accounts (WGA) which is 1,500 sets of accounts for public funded bodies. I used FOI to http://bit.ly/wdtk-coins-5[request the 2008/09 WGA data] but to no avail. I also asked for the report from the audit office for WGA--which I hoped would explain the reasons the WGA was not in a suitable state to be released. That was http://bit.ly/wdtk-coins-6[also refused].

经过一段时间的研究，发现数据库中似乎有很大一部分的数据是缺失的，政府整体财务报告（Whole of Government Accounts (WGA)），其中包括1500组公共部门的合并财务报告，就是不公开的。我曾经用FOI申请了 http://bit.ly/wdtk-coins-5[2008-2009年度的WGA信息]，但是显示无效。我还申请了负责WGA的审计部门的报告，希望能解释为什么WGA的信息是不能公开的，不过这个申请 http://bit.ly/wdtk-coins-6[也被拒绝]了。

2011年12月，WGA在COINS中被公开了。我想为WGA提供的合并财务报告中的1500个组织各自建立一个完整的信息包，为了在这样的实践中得到足够的指导和帮助，我用另外一个理由使用了FOI：为了确保在英国信息透明计划指导下公布的信息都被合理的解释并包含必要的内容。我通过FOI申请了WGA中各个公共部门的 http://bit.ly/wdtk-coins-7[完整财务信息]。

&mdash; _丽莎·埃文斯(Lisa Evans)，卫报_
****

=== 试试游说(Wobbing)数据！

利用信息自由法案，有时也被称之为数据游说，是非常有效的工具。但它需要一定的方式方法，往往更要靠毅力。这里用三个我作为调查记者的亲身经历，来说明数据游说的长处与挑战。

==== 个案研究1：农业补贴

欧盟每年将近补贴600亿欧元给农民以及整个种植业。没错，是每年。从20世纪50年代后期开始持续到现在，这一直作为政策上对贫穷农民补贴。然而在2004年丹麦，作为FOI的第一次突破，揭露了这仅仅是政策上的表述而已，并没有落到实处。小农场主们像他们时常私下里或公开抱怨的那样不断挣扎着，事实上大部分的钱都流向了少数大地主手中或农产业里。所以，很显然我想知道：在欧洲都是这样的吗？

2004年的夏天，我向欧盟委员会索要数据。每年二月，委员会都会收到各成员国的数据。数据显示谁申请欧盟拨款，受资助的受益人得到多少，以及他们是否通过耕作他们的土地、开发他们的地区或者出口奶粉而得到。当时，委员会以存在CD光盘的CSV格式文件收到数据。虽然数据量很大，但原则上这都很容易完成的工作。只要你能拿到数据，那就简单了。

在2004年，委员会拒绝公开数据；主要的争论点是，数据上传到数据库之后还要做大量工作，才能把想要的数据提取出来。按欧洲司法监察机构的说法来看，这就是_行政失当_。现在你可以在http://bit.ly/eu-wobbing[wobbing.edu的网站上]找到有关这个案例的全部文档。回到2004年，我们那时候可没有时间一步一步走法律程序。我们想要的是数据。

[[FIG044]]
.农业补贴网站 (Farmsubsidy.org)
image::figs/incoming/04-BB.png[float="0"]

所以我们和一些同伴组成团队，为了获取数据跑遍了欧洲的每一个国家。英国、 瑞典、和荷兰的同事拿到了2005 年的数据。芬兰、 波兰、 葡萄牙、 西班牙、 斯洛文尼亚和其他一些国家也开放了他们的数据。即使在最难的德国，我也获得了重大突破，拿到了威斯特伐中省的北莱茵-利亚(North Rhine-Westfalia)一些2007 年的数据。为了拿到数据我不得不走上法庭——最终的结果是，一些相当优秀的报道文章刊登在了http://bit.ly/stern-wobbing[Stern and Stern在线新闻杂志]上。

难道丹麦和英国最早开放他们的数据是巧合吗？不一定。从更大的政治图景来看，彼时农业补贴问题正在世界贸易组织谈判中被施压。因为丹麦和英国属于欧洲里更偏向自由派的国家，所以这些透明的政治风向更可能吹向他们。

报道仍在继续，更多的事件和数据请查阅http://farmsubsidy.org/[农业补贴官方网站]。

心得：去各个地方“游说”数据。在欧洲，我们有多种多样到令人吃惊的信息自由法，并且不同的国家在不同时期会有不同的政治利益关系。你大可以好好利用。

.知晓你的权利
****
当你发布数据的时候，你不是应该考虑一下版权问题和其他有关数据的权利？虽然你应该和你的法律团队一起搞清所有的法律问题，但一般来说：如果数据是由政府发布的，那你既不用请求宽恕也不用请求许可；如果这是由组织发布的，且数据并不是为了盈利，那你也不用太过操心；如果这是组织发布的数据且是出于盈利目的，那你一定要请求允许。

&mdash; _西蒙·罗杰斯(Simon Rogers)，卫报_
****

==== 个案研究2：副作用

吃药的时候我们都是被拿来作试验的小白鼠。药物都会有副作用。尽管众所周知，我们会在衡量过潜在的好处和风险之后，再作出（是否服用的）决定，但不幸的是这一决定往往都不是明智的。

++++
<?dbfo-need height="1in"?>
++++

青少年们是为了拥有更光滑的皮肤服而服用抗粉刺药，而不是想让自己变的抑郁。这样的事恰恰就发生在一种抗粉刺药上，青少年服用之后变得抑郁，甚至导致自杀。这种危险的特定药物副作用，显然是记者们追逐的新闻题材，可惜副作用案例不易找到。

有关药物副作用的数据是有的。生产者必须定期向卫生当局提供观察到的有关副作用的情况。从药物获准上市开始，国家或者欧洲有关当局就已经拿到这些数据。

同样，在国家层面的最初突破口始于丹麦。在一个由丹麦-荷兰-比利时三国团队进行的跨境研究期间，荷兰也开放了他们的数据。数据游说的另一个例子： 我们的这个案例可以明确指出一点，荷兰当局的数据可以在丹麦拿到。

但这是个真实的故事：在欧洲已经发现有自杀倾向的年轻人很悲剧地因为服食药物而最终自杀。新闻工作者、 研究人员和年轻受害者的家属都在用尽全力去获取这些信息。欧洲监察员也在帮助推动在欧洲药品管理局的透明公开，而且看起来http://bit.ly/eu-ombudsman[好像成功]了。所以现在的任务落到了记者头上，摆出数据并彻底剖析这些材料。我们都是豚鼠吗？或正如一位研究人员所说，监控机制健全吗？

心得：关于信息透明公开的问题绝对不要妥协。坚持下去并且随着故事的发展推进下去。事情可能会有很好的转机，或许因此在短时间内就能拿到更好的数据，写出更好的报道。

==== 个案研究3：走私死亡

最近的历史发展对全人类来说都异常煎熬，尤其是在战后和转型时期。记者又如何可以获得“干货”数据进行调查, 譬如，当最近十年战争的赢家开始掌权的时候？这正是一个由斯洛文尼亚、 克罗地亚、 波斯尼亚记者所组成的团队所追求的目标。

该团队旨在调查90年代初联合国禁运期间前南斯拉夫境内的武器交易。工作的基础是议会对这个议题的调查记录。然而，为了记录下来他们的运送路线并了解交易结构，记者们还必须要去跟踪港口的船只数量和卡车的车牌。

斯洛文尼亚议会委员会曾主持调查从巴尔干战争谋取暴利的问题，但从来没有得出什么结论。然而他们尚有解密文件和数据中极富价值的线索，包括斯洛文尼亚团队通过信息自由请求拿到的6,000页文件。

在这种情况下,数据还必须从文件中提取出来并在数据库中分类整理好。通过补充更多数据一同进行分析和研究，他们绘制出了大量的http://bit.ly/kaasogmulvad-smuggling[非法武器贸易路线]。

整个团队非常的成功，结果也很http://bit.ly/journalismfund-smuggling1[独特]，并且为团队赢得了他们的第一个奖项。最重要的是，这些报道影响了整个地区。同时，其他国家的记者还能够跟进调查，继续挖掘这些杀伤武器货物运输路径的报道。

心得：关键是挖掘好的原素材，哪怕是从最意想不到的地方着手，再结合一些已经公开的数据进行分析。

&mdash; _布里奇特·阿尔夫特(Brigitte Alfter)，Journalismfund.eu_

.FOI with Friends
****
Many Balkan countries have issues with government corruption. Corruption is often even higher when it comes to accountability of the local governments in those countries. For several months a group of Serbian journalists around the Belgrade-based http://www.cins.org.rs/[Centre for Investigative Reporting] have been questioning different types of FOI documents from over 30 local municipalities in 2009. Prior to that, almost nothing was accessible to the public. The idea was to get the original government records and to put the data in spreadsheets, to run basic checks and comparisons among the municipalities and to get maximum and minimum figures. Basic indicators were budget numbers, regular and special expenses, salaries of officials, travel expenses, numbers of employees, cell phone expenses, per diems, public procurement figures, and so on. It was the first time that reporters had asked for such
information.

The result was a comprehensive database that unravels numerous phony representations, malfeasances, and corruption cases. A list of the highest-paid mayors indicated that a few of them were receiving more money than the Serbian president. Many other officials were overpaid, with many receiving enormous travel repayments and per diems. Our hard-earned public procurement data helped to highlight an official mess. More than 150 stories came out of the database and many of them were picked up by the local and national media in Serbia.

We learned that comparing the records with the comparable data from similar government
entities can display deviations and shed light on probable corruption. Exaggerated and unusual expenses can be detected only by comparison.

&mdash; _Djordje Padejski, Knight Journalism Fellow, Stanford University_
****

=== 从网络获取数据

你是否已尝试了各种方法，却仍未获得需要的数据？也许有时你在网页上已经找到所需数据了，只是上面并没有下载按钮，复制粘贴功能也用不了。不要着急，这里有一些实用的方法，比如你可以：

++++
<?dbfo-need height="1in"?>
++++

  * 从基于网页的API接口获得数据，这包括在线数据库提供的用户界面以及各种新式的网络应用（比如Twitter、Facebook等等）。这是获得政府和商业机构数据的好方法，在社交网站上也很有效。
  * 从PDF文档提取数据。这很困难，因为PDF是一种针对打印机的格式，里面存储的数据结构和一般文档极为不同。从PDF提取数据比从一本书中提取要困难得多，但还是有一些工具和操作指南可以帮助你完成这项工作。
  * 利用有网页抓取功能的网站。在这类网站上，你可以借助其提供的实用工具或是自己写一段建议代码从普通网页上提取结构化的内容。这种方法十分强大，适用于许多情况，但这要求你了解一些关于网页的知识。

借助这些强大科技功能的同时，也别忘了简单易用的方法：花点时间搜索机器可读的数据，或者给持有所需数据的机构打电话都可能会帮助你拿到你想要的数据。

在本节我们将展示一则从HTML网页上极为简单的抓取范例。

==== 什么是机器可读的数据？

大多数方法的目的都是为了获得机器可读的数据。机器可读的数据是为方便计算机处理而生成的，而不是为了向人类用户展示。这些数据的结构与其内容相关，但与数据的最终展示形式不同。简单的机器可读数据格式包括CSV、XML、JSON和Excel文档等等，而Word文档、HTML网页和PDF文档则更侧重于数据在视觉上的呈现。PDF是一种与打印机交互的语言，它记录的信息并不是一个个字母，而是线与点在页面上的位置。

==== 从网页上抓取什么？

这种事情每个人都做过：你在某网站上浏览时发现一个有趣的表格，想把它复制到Excel中便于计算或是存储下来。但有时这种方法并不奏效，有时你所需要的数据又分布在好几个网站的页面上。手动复制粘贴太乏味了，而用一些小代码可以令你事半功倍。

网页抓取的一大优势是其几乎可以用于所有网站，无论是天气预报还是政府预算。即便该网站并未提供针对原始数据访问的API接口，你同样可以抓取。

==== 网页抓取的局限性

抓取不是万能的，也会遇到障碍。网页难以抓取的主要因素有：

  * HTML编码拙劣，结构信息很少或者压根没有，常见于早期的政府网站。  
  * 网站有防止机器自动访问的验证系统，如CAPTCHA验证码和付费系统。
  * 使用浏览器Cookies存储用户信息获得用户动作再给出内容的会话系统。
  * 网站未提供完整的分类列表和通配符搜索功能。
  * 服务器管理员对大量访问做出了限制。

另一方面，法律限制也会成为障碍。部分国际承认关于数据库的权利，这会限制你重复利用在网络上公开发表的信息。有的时候，你可以无视这些法律条款仍然进行抓取，这取决你所在地的司法管辖权，如果你是记者的话也会有一些特殊的便利。抓取免费的政府数据一般没事，不过在发表之前还是应当再查一遍。商业组织和部分NGO对数据抓取行为采取几乎零容忍的态度，他们会指控你“破坏”他们的系统。其他可能侵犯个人隐私的数据则会触犯数据隐私法令，也与职业道德相背。

.Patching, Scraping, Compiling, Cleaning
****
The challenge with huge swathes of UK data isn't getting it released--it's getting it into a usable format. Lots of data on hospitality, MPs' outside interests, lobbying and more is routinely published but in difficult-to-analyze ways.

For some information, there is only the hard slog: patching together dozens of Excel files, each containing just a dozen or so records, was the only way to make comprehensive lists of ministerial meetings. But for other information, web scraping proved incredibly helpful.

Using a service like ScraperWiki to ask coders to produce a scraper for information like the Register of MPs' interests did around half of our job for us: we had all MPs' information in one sheet, ready for the (lengthy) task of analysing and cleaning.

Services like this (or tools such as Outwit Hub) are a huge help to journalists trying to compile messy data who are unable to code themselves.

&mdash; _James Ball, the Guardian_
****

==== 抓取工具

有许多程序可用于从网站提取大量信息，包括浏览器扩展程序和一些网络服务。http://www.readability.com/[Readability]（从网页上抓取正文）和http://www.downthemall.net/[DownThemAll]（批量下载文件）工具可以在部分浏览器上自动处理繁琐的任务，Chrome浏览器的http://bit.ly/chrome-scraper[Scraper插件]可以从网站上提取表格。针对开发者的扩展程序FireBug（针对Firefox浏览器，Chrome、Safari和IE已内置类似功能）可以让你清晰了解网站结构和浏览器与服务器之间的通讯。

https://scraperwiki.com/[ScraperWiki]网站提供包括Python、Ruby、PHP在内的多种语言供用户自行编写抓取代码。这使得用户不再需要在本地安装语言环境便可编码进行抓取工作。另外Google电子表格和Yahoo! Pipes等网页服务也提供从其他网站提取内容的服务。

==== 网页抓取工具如何运作？

网络抓取工具通常是用Python、Ruby或PHP写成了一小段程序代码。具体选择哪一种语言取决于你的周围，如果你的新闻机构或者同城市的同行中有人已开始用某种语言进行编写，你最好也采用同样的语言。

虽然前文提到的点击选择工具可以帮助你上手，但真正复杂的步骤是确定正确的页面和页面上存储所需信息的正确元素。这些步骤的关键并不在于编程，而在于对网站和数据库结构的了解。

浏览器在展现网页时主要运用以下两种技术：通过HTTP协议与服务器通讯，请求获得文档、图片、视频等指定资源；然后获得以HTML编码写成的网页内容。

==== 网页的构造

每个HTML网页都是由有一定结构层次的“盒子”构造的（由HTML``标签''定义）。大的“盒子”中又会包含小的“盒子”，就像一个表格中有行、列和单元格一样。不同的标签有不同的功能，可以定义“盒子”、表格、图片或者是超级链接。标签也有附加属性（比如唯一标识符），并可被定义在“类”中，这便于我们定位和获取文档中的独立元素。编写抓取工具的核心就是选择合适的元素从而获取对应的内容。

查看网页元素时，所有代码都可按照“盒子”进行分割。
 
在开始抓取网页之前，你需要了解HTML文档中会出现哪些类型的元素。举例来说，+<table>+会形成一个表格，在其中+<tr>+定义了行，+<td>+又把行细分为单元格。最常见的元素类型是+<div>+，简单来说它可以定义任何内容区域。认知这些元素最简单的方法就是利用浏览器上的http://bit.ly/developer-toolbar[开发者工具]，在将鼠标悬停在网页的特定区域上时，这些工具就会自动显示该区域对应的代码。

标签就像书的封面一样，告诉你哪里是开头，哪里是结尾。+<em>+_表示文字从此处开始以斜体显示_，+</em>+则标明斜体字到此结束。多简单！

==== 例子：使用Python抓取核事件

国际原子能机构(IAEA)门户网站上的http://www-news.iaea.org/EventList.aspx[新闻栏目]下记录了全球各地的放射性事故（栏目名正申请加入“怪异标题俱乐部”）。该网页使用简单、类似博客形式的结构，便于抓取。

[[FIG045]]
.国际原子能机构(IAEA)门户网站 (news.iaea.org)
image::figs/incoming/04-CC.png[float="none"]

首先，在https://scraperwiki.com/[ScraperWiki]上新建一个Python抓取工具，然后你将看到一个基本空白的文本框，里面有些基本的框架代码。同时在另一个窗口中打开http://www-news.iaea.org/EventList.aspx[IAEA网站]，并打开浏览器的开发者工具。在“元素”视图下，找到每条新闻标题所对应的HTML元素，开发者工具会明确指出定义标题的代码。

进一步观察可以发现，标题用+<h4>+定义在+<table>+中。每个事件都有一个单独的+<tr>+行，里面还有事件描述和日期。为了获取所有事件的标题，我们应当用一定的方法按顺序选择表格中每一行，然后获得标题元素中的文本。

要将这些进程写成代码，我们需要明确具体的步骤。我们先玩个小游戏感受一下什么是步骤。在ScraperWiki的界面中，先尝试为自己写一些指引，你要通过代码完成哪些工作，就像食谱中的工序一样（每行开始前写一个“#”以告诉Python这行不是计算机代码）。例如：

----
# 寻找表格中的所有行
# 不要让独角兽在左侧溢出（注：IT冷笑话）
----

写的时候要尽可能准确，不要认为程序真的懂你要抓取哪些内容。

写了几行伪代码后，我们再来看看真正代码的前几行吧：

----
import scraperwiki
from lxml import html
----

在第一段中，我们从库（预先写好的代码片段）中调用了已经存在的功能，+ScraperWiki+在此段代码中已经提供了下载网站的功能，+lxml+则是一个用来对HTML文档进行结构分析的工具。告诉你个好消息，在ScraperWiki中写Python的抓取工具，前两行都是一样的。

----
url = "http://www-news.iaea.org/EventList.aspx"
doc_text = scraperwiki.scrape(url)
doc = html.fromstring(doc_text)
----

然后，代码定义了变量名称：+url+，其值为IAEA的网页地址。这行告诉抓取工具，有这么个事情，我们要对他做些动作。注意这段URL网址在引号中，表明这不是一段代码，而是一个_字符串_，一串字符序列。

然后我们将这段+URL+变量放入一个指令，+scraperwiki.scrape+。这段指令会执行已定义好的动作：下载网页。这段工作完成后，它将执行指令将内容输出到另一个变量+doc_text+中，然后在+doc_text+中存储的就是网页的文本了。不过这段文本并不是你在浏览器中看到的样子，它是以源代码形式存储的，包含了所有的标签。由于这些代码不容易解析，我们再用另一个指令+html.fromstring+生成一个特殊的格式，方便我们分析其中元素，这种格式叫做文档对象模型(DOM)。

----
for row in doc.cssselect("#tblEvents tr"):
link_in_header = row.cssselect("h4 a").pop()
event_title = link_in_header.text
print event_title
----

最后一步，我们使用DOM搜索表格中的每一行，并获取事件的头部获取标题。这里有两个新感念：for循环和元素选择器(+.cssselect+)。for循环的工作很简单，它会遍历项目清单，给每个项目分配一个别名（在本段中就是每行+row+），然后对每个项目都执行一次缩进部分的指令。

另一个概念——元素选择器，指的是利用特定语言在文档中查找元素。CSS选择器通常被用来在HTML元素上添加布局信息，我们可以利用它在页面中精确的定位元素。在本段代码的第6行，我们使用+#tblEvents tr+选出+<tr>+标签中所有选择器ID为+tblEvents+的行（ID前需加“#”作为标识）。这段代码将会返回符合条件的+<tr>+元素列表。

接着在第7行，我们使用另一个选择器查找+<h4>+标签（标题）中的+<a>+标签（超级链接）。这里我们一次只找出一个元素（因为一行中只有一个标题），所以在找到后我们需要通过.+pop()+命令将其输出。

请注意，DOM中的某些元素含有实际的文本，也就是非程序语言的文本。对于这些文本，我们在第8行使用+[element].text+命令。最后，在第9行，我们将结果输出至ScraperWiki的控制台。完成后，只需在抓取工具中点击“运行”，小窗口上便会一一列出IAEA网站上的事件名称了。

[[FIG046]]
.运行中的抓取器 (ScraperWiki)
image::figs/incoming/04-DD.png[scale="90",float="none"]

++++
<?dbfo-need height="1in"?>
++++

现在一个基础的抓取工具就开始运行了。它将下载网页，将其转换为DOM格式，然后你就可以从中选择、获取特定内容了。在这个框架下，你可以试着利用ScraperWiki和Python的帮助文档解决剩下的问题：

  * 你能找到每个事件标题中的超级链接地址吗？
  * 你能利用CSS类名选择包含日期和时间的小“盒子”并将其中文本输出吗？
  * ScraperWiki为每个抓取工具分配了一个小的数据库用于存储结果，请从文档中复制相关事例，将获取到的事件标题、超级链接和日期存储在一起。
  * 事件列表不止一页，你能让抓取工具翻页获得之前的事件信息吗？

在尝试解决这些问题的同时，你也可以在ScraperWiki上逛逛。网站上很多现成抓取工具中都有实用的案例，其中的数据也很有用。这样你就不需要从头开始敲代码了，利用类似的案例，对代码进行改动，再部署到自己的问题上就可以了。

&mdash; _弗里德瑞克·林登伯格(Friedrich Lindenberg)，开放知识基金会_

.Scraping a Public Database
****
Some French physicians are free to choose their own rates, so that one can pay between €70 and €500 for a 30-minute visit at an oncologist, for instance. This data regarding rates is legally public, but the administration provides only a hard-to-navigate online database. In order to have a good view of the doctors' rates for Le Monde, I decided to scrape the entire database.

That's where the fun began. The front-end search form was a Flash application that redirected to an HTML result page via a POST request. With help from Nicolas Kayser-Bril, it took us some time to figure out that the application used a third page as a ``hidden'' step between the search form and the result page. This page was actually used to store a cookie with values from the search form that was then accessed by the results page. It would have been hard to think of a more convoluted process, but the options of the cURL library in PHP make it easy to overcome the hurdles, once you know where they are! In the end, getting hold of the database was a 10-hour task, but it was worth it.

&mdash; _Alexandre Léchenet, Le Monde_
****

++++
<?dbfo-need height="1in"?>
++++

=== 把网页作为数据来源 ===

如何找到只在网络上存在的事物？不管你要找电邮地址、网址、图片或是维基百科条目，在本章你都可以了解到相关的工具可它们背后的故事。

==== 网页工具

首先，你需要了解一些探索一整个网站而不是几个页面的服务。

Whois::
  如果你访问 whois.domaintools.com[whois.domaintools.com]（或在Mac上的Terminal应用中输入whois www.example.com），你就可以得到任意网站的基本注册信息。近年来，很多网站所有者在注册域名时选择“隐私保护”模式，将注册信息隐藏。但大多数情况下你还是能够查到域名注册者的姓名、住址、电邮地址和电话号码。同时，你也可以输入数字型的IP地址，查找拥有该IP的服务器所属的组织或个人。在追查散播侮辱性言论和恶意攻击的用户时，这些服务特别方便，因为大多数网站都会记录访问者的IP地址。

Blekko::
 http://blekko.com/[搜索引擎Blekko]在抓取网页时使用了不常用的技术获得更核心的统计数据。在域名后输入“/seo”即可获得该URL包含的信息。
  <<FIG048>>网页的第一个标签按人气将链入该域名的网站进行了排序。这对于获知网站的覆盖面范围有多大极有帮助，由于Blekko使用了进站地址作为排序依据，部分网站的排名会比他们的Google排名更高。<<FIG049>>展示了与该网站位于同一主机的其他网站域名。诈骗和垃圾网站常常会在同一个主机上建多个网站，在他们之间互相引用和链接，形成人气的假象。这些网站看起来都是各自独立的，甚至连注册信息都截然不同，但他们经常因为节省成本的原因架设在一个主机上。这些数据可以让你了解所搜索的网站背后的商业架构。

[[FIG047]]
.搜索引擎Blekko (Blekko.com)
image::figs/incoming/06-PP-01.png[float="none"]

[[FIG048]]
.了解网站的人气排行：谁链接了谁？另一项实用的功能标签是“抓取数据”，尤其是“共用主机”部分. (Blekko.com)
image::figs/incoming/06-PP-02.png[float="none"]

[[FIG049]]
.查看垃圾和诈骗网站 (Blekko.com)
image::figs/incoming/06-PP-03.png[float="none"]

Compete.com::
 http://www.compete.com/[compete.com]通过对美国网民的调查，为大多数网站提供细节化的用户数据，其中一些基本的数据是免费开放的。选择“站点信息”标签后输入域名(<<FIG0410>>)，就可得到该站点在过去一年的流量，以及用户的访问数量及频率(<<FIG0411>>)。由于这些数据是基于调查所得，所以有些模糊，不过我通过将此数据与网站内部分析数据对比发现，他们还是相当准确的。在比较两家网站方面，这是相当好的数据来源，尽管双方的数据都不太精确，但仍能准确反映两者相对的人气状况。由于只对美国网民进行调查，Compete.com在对面向国际用户的网站支持上很弱。

[[FIG0410]]
.Compete.com的站点信息服务 (Compete.com)
image::figs/incoming/06-PP-04.png[float="none"]

[[FIG0411]]
.用户的趋势和需求是什么？分析网络上的热点 (Compete.com)
image::figs/incoming/06-PP-05.png[float="none"]

Google的站点搜索::
  使用“site:”参数搜索特定域名下的内容是个好方法。在关键词后加入“site:example.com”搜索，Google会仅展示指定域名下的内容。你还可以将范围进一步缩小的域名下的目录，比如“site:example.com/pages/”，获得更精细的结果。有时域名所有者发布的一些信息并没有刻意去展示，使用正确的关键词可以有效发掘出这些内容。

==== 网页、图片和视频

有时你并没有对整个网站产生兴致，或许只关心特定事件的相关消息。以下的工具将展示网民在网上阅读、反馈、复制和分享内容的不同视角。

Bit.ly::
  在分析用户分享特定链接的行为时，我总是会用http://bit.ly[Bit.ly]。在网站上输入需要查询的网址，然后点击“信息页+”链接，便可得到完整的数据统计页面（首次使用时需要选择“整合Bit.ly链接”）。你会从中了解该页面的人气情况，包括在Facebook和Twitter上的热度，在下方还会呈现由backtype.com生成的用户关于该网页的公开对话。我发现在试图了解一个网站或网页为何如此热门时，这种流量和对话的组合统计十分有帮助，还可以精确定位目标人群。例如，它让我了解到主流对草根分享和莎拉•佩林的认识都是错的。

++++
<?dbfo-need height="1in"?>
++++

推特::
  随着越来越多的人开始使用微博客服务，微博已成为衡量用户对特定内容分享和交流的实用工具。操作起来十分简单，你只需将网址放入搜索框，也许还需要在搜索结果页面上点一下“更多推文”获得所有结果。

Google网页快照::
  网站发布者在发现页面内容有争议时，可能会将其删除或是在不做任何通知的情况下进行修正。如果你怀疑自己遇到了这种情况，首先就应当看看Google对该页生成的上一次快照。由于Google抓取网页的频率越来越高，这要求你必须在发现情况可疑后的几小时内就进行快照查询。在搜索框中输入要查询的网址，然后在结果页上点击向右的箭头，即可看到页面预览。运气好的话，预览结果上方会有“网页快照”链接，点击即可获得Google对该网页的存档结果。如果网页加载缓慢，你可以试试页面最上方的“纯文本”选项获得更简洁的页面。打开快照后，你最好进行截屏，或者把相关的信息复制下来，因为随着Google的下一次页面抓取，这一结果可能在任何时刻被覆盖。

互联网档案馆的时间机器::
  你也许会需要特定页面在过去数年、数月间的长期改动情况，http://archive.org/web/web.php[互联网档案馆的时间机器服务]可以帮你，它会定时对人气最高的页面进行截图。访问网站，输入需要查找的网页地址，如果有存档的话，页面上就会显示出带有链接的日历，接下来选择具体日期即可查看。时间机器服务将展示该网页在当时的大致情形，其中的版式和图片可能已经失效，但通常这对于理解网页内容没什么影响。

查看源代码::
  这可能会花点时间，但开发者的确经常在网页的HTML代码中留下评论或者其他线索。不同的浏览器有不同的菜单设置，但你总能找到“查看源代码”获得原始HTML的选项。你不需要理解其中的机器语言，只需要找寻散落在其中的文本内容。即使代码中只提到过版权声明和作者的名字，这通常也成为了解页面创建过程和目的的重要线索。

TinEye::
  有时网络上的图片没有标注来源，传统的搜索引擎功能没什么用，但你又需要知道它的来源。http://www.tineye.com/[TinEye]提供了一种特别的“反向图片搜索”功能，提交图片后它就会在网络上中找出相似的图片。TinEye使用了图像识别技术，对于被裁减、失真和压缩的图片也很有很好效果。当你怀疑某图片被裁减过用来伪造原创作品或是曲解原意时，这个功能可以帮你找到原始来源。

YouTube::
  点击每个视频右下方的“统计”按钮就可得到观看者的详细信息。尽管数据有些笼统，但其对于了解观看者的所在地和观看时间很有帮助。

==== 电子邮件
在研究电子邮件时，你经常想了解发件人的具体身份和位置。虽然没有现成的工具完成这项供需，但了解一些所有电邮中有的隐藏报头十分有帮助。报头类似邮戳，可以揭示发件人数量惊人的信息。尤其是，它往往包含了电邮发送时使用机器的IP地址，这类似于电话中的来电号码。接下来，你可以对该IP地址进行whois查询，得到其所属的组织。如果得到Comcase或AT&T之类向消费者提供网络的服务商，则可去MaxMind查询该IP的大致位置。

在Gmail中查看邮件报头，打开信件后，展开上方“回复”按钮右侧的下拉菜单，选择“显示原始邮件”，然后在新窗口就会展示信件的隐藏信息了。

代码最上方会有十几行以冒号结尾的参数，你所需要的IP地址就在其中某行。表示IP的参数多种多样，如果发件人使用Hotmail，则该行显示+X-Originating-IP:+，而Outlook和Yahoo的信件会在首行标记+Received:+。

查询该IP我得知其属于英国的一家名为“Virgin Media”的ISP，然后我通过MaxMind定位服务得知其来自我的家乡——剑桥。这意味着我可以充分确信发件人的确是我的父母，而不是诈骗犯。

==== 流量趋势
如果你需要调查一个很广泛的话题，而不是特定的网站或事物，那你需要这些让你洞察细节的工具:

维基百科条目流量::
  如果你对公众对特定话题或人物的热度变化有兴趣，可以在http://stats.grok.se/[stats.grok.se]查看维基百科任意页面每日的访问量。网站页面略显错草，但它可以让你深度挖掘所需信息。输入你感兴趣的事物就可得到该页面一个月以来的流量情况。图表会显示指定月份中每日的访问量。不过你每次只能选一个月的数据查看，这要求你多次选择才能得到更长时期的数据。

Google Insights::
  使用http://www.google.com/insights/search/[Google Insight](<<FIG0412>>)可以帮助你了解公众的搜索习惯。输入一对热门关键词，比如“Justin Bieber vs Lady Gaga”，就可以得到两人搜索数据随时间变化的关系图标。Google还提供多种选项提炼数据，可以限定地理位置和时间参数。此服务唯一的劣势是其只提供搜索数据的相对关系，而不提供绝对值，在转换数据时会有困难。

[[FIG0412]]
.Google Insights (Google) 
image::figs/incoming/06-PP-06.png[float="none"]

&mdash; _皮特·沃登(Pete Warden)，独立数据分析师、开发者_

=== 《卫报》数据博客的众包式数据

根据维基百科的http://en.wikipedia.org/wiki/Crowdsourcing[定义]，"众包(Crowdsourcing)是指一种分布式的解决问题和完成工作的做法，通常包括将任务外包给多个人组成的网络，即'大众(Crowds)'"。以下是对西蒙·罗杰斯的采访记录，他在其中介绍了《卫报》数据博客如何通过众包服务，对议员开支丑闻、毒品滥用以及莎拉·佩林(Sarah Palin)的邮件进行的数据挖掘：

有时候，你会拿到大量的文件、统计数字或者文字报告，但你不可能一个人看完全部资料。还有就是，虽然你可能有资料在手，但是却很难看懂或者格式混乱，在这种情况下你也无计可施。这就是为什么众包可以帮大忙。

《卫报》有很多读者，可以说是帮手众多。如果现在有一个有意思的项目，我们需要人来录入数据，就可以让这些读者帮助我们。这是我们在调查http://mps-expenses.guardian.co.uk/[国会议员开销]时所采用的方法。我们有45万个文件，但时间非常少，几乎干不了什么事情。那除了向读者开放项目，还能有什么更好的方法么？

[[FIG0413]]
.史蒂芬·庞德(Stephen Pound)杂项开销的摘要副本（卫报）
image::figs/incoming/04-EE.png[float="none"]

调查议员花销的项目中，我们得到了大量的线报。我们知道了比数据本身更多的背后故事。从信息交流方面讲，这个项目是非常成功的。大家真的很喜欢参与进来。

我们现在正在与《MixMag》杂志在一个http://bit.ly/guardian-drugs[吸毒调查项目]上展开合作，结果也是异常出色。如果从调查人数上来说，这个项目的覆盖面估计要比英国犯罪调查还要大，这真是一个非常聪明的做法。

这两个项目所关注正是大众切实关心的问题，所以大家都愿意花时间参与。我们做过的大部分众包服务其实都是依赖于一些对资料异常感兴趣的人。在调查议员费用的项目伊始，我们收到了大量信息，但这种势头很快就没有了。但有是有人坚持不懈地翻看每页资料，寻找数据中的异常和故事。其中有个人看了3万页。他们知道不少东西。

我们还利用众包来做http://bit.ly/guardian-palin-papers[莎拉佩林邮件的项目]。众包再次帮了我们很大忙，帮助我们整理原始信息并且提炼故事。

在提炼故事上，众包在我们的项目中发挥了出色的作用。大家很喜欢参与，而这也让《卫报》'看起来很棒'。但就收集数据方面来看，我们尚无频繁使用众包服务。

一些我们运作得好的众包项目，多半是传统的调查。当你问别人的经历、生活或者工作，他们会很配合，因为对这些问题大家不太可能编故事。他们会说出他们的感受。当我们向大众参与我们的项目工作时，必须设定一个框架，好让大家给出你所能信任的数据。

说到数据的可靠性，我想http://www.oldweather.org/[以前的天气]那个项目的结果就非常好。每个问题他们都会找十个人来回答，这就很好确保了数据的准确性。而在调查国会议员费用项目中，为了避免议员给自己脸上贴金，我们尽量减少议员自己上网和篡改记录的可能。但这种情况不可能一直避免。你所能做的只是注意某些特定的URLs，或者看它们是否来自于伦敦的西南城区。所以，想要完全避免这种情况有点难度。分发出去的数据也并不总是可靠的。即使故事很好，但拿不到原始数字的话我们也不敢放心使用。

如果让我给有抱负的数据记者就众包服务收集数据方面提点建议，我会说选题很重要，选择那些大众切实关注的，并且淡出媒体视野后持续关注的事情去做调研。而且，如果你做的东西更像是个游戏，这会更吸引民众参与。我们第二次做议员费用调查项目的时候，就很像一个游戏，大家会有一个一个任务去完成。设计特别的任务确实会有明显的效果。这其中有很大差别。这就像指着山一样的大量资料，然后对大家说“把它们看完”，我觉得这会让你的工作困难重重而且吃力不讨好。所以我想，把整件事儿做得有意思还是很重要的。

&mdash; _摘自数据新闻博客的 玛丽安·包查特(Marianne Bouchart) 对 卫报西蒙·罗杰斯(Simon Rogers) 的采访_

=== 《卫报》数据博客利用众包的报道奥运票务

我认为，大众反响最热烈的众包项目就是对http://bit.ly/guardian-olympics[奥运门票抽签的调研]。成千上万的英国人都想得到2012奥运会的门票，那些没买到票的人就很生气。人们花了几百英镑订票，但最后得知什么都没买到。但其实谁也不知道实际情况，说不定大多数都很满意，而只有少数人在大声抱怨。于是，我们试图查明事情真相。

我们认为，由于没有任何相关的数据，最好的办法就是去问人们的想法。由于样本的不平衡性，我们觉得这不是小事。

我们做了一个谷歌问卷，在其中问了http://bit.ly/guardian-olympics2[非常具体的问题]。这份问卷本身比较长，包括订了多少钱的门票，信用卡扣款多少，最后结果如何等等诸如此类的问题。

[[FIG0414]]
.How many Olympic tickets did you get?: the readers' results (the Guardian)
image::figs/incoming/04-FF.png[float="0"]

我们在网站的上方放了一小张图片，很快这份问卷就传播开来。这里有一个关键，你不能只是想“关于这个故事我想要知道什么？”，而是“大家现在有什么愿意告诉我的？”。只有当你勾起大家的交流热情，众包才会成功。虽然这是我们对众包服务的初期尝试，但大家对这个项目的回应异常热烈。头一个小时我们收到一千份调查结果，而到了第一天末就有七千份了。

拿到这么多数据，我们对数据的展示也变得认真起来。最开始我们不知道这个项目能做成什么样。所以我们添加了一些说明：比如《卫报》的读者群可能比其他人富有一些，购票时比较失望的人可能更愿意回应我们的调研，等等。

我们当时还不知道这些调查结果有多大的价值。最后我们整理出七千份不错的回复用于数据分析，发现大约一半订购门票的人一无所获。我们把数据整理出来，由于大量民众的参与，结果也非常有意思。

几个星期后官方报告出来了，结果和我们的数据令人震惊的接近。几乎是完全正确。我觉得这个项目的成功有部分运气的成份，但这么多人的参与也是原因之一。

比如一开始你只是让读者对这个事情进行评论，那么你得到的结果将会非常有限。所以从开始就要考虑：“对于我想要的信息，最好的工具是什么？”是论坛评论么？或是做一个应用程序？如果需要做应用程序，你必须考虑“中间投入的时间是值得的么？还有投入的资源是值得的么？”

在这种情况下，我们想到了谷歌调查问卷。别人回答了问卷，返回给你的结果就是电子表格中的一行。这意味着，即使数据仍在更新，结果仍在产生，打开电子表格就可以很直接看到所有的结果。

我可以用谷歌进行后续分析，但我还是把结果下载到微软Excel里面进行整理，比如从低到高排序之类的。有人在花销一栏填写的是文字而不是数字，我也要把这类问题进行修改。我决定尽量少的剔除调查结果。所以我不光选取了符合标准的问卷，而是试着解决各种书写问题。有人使用外国货币，所以我得把它们换算成英镑，这些事做起来是有点辛苦。

但整个分析也就用了几个小时，我去掉了那些明显胡填的结果。很多人在问卷中承认他们在门票上没花一分钱。这有点搞笑，但也没问题。在超过七千万个条目中只有不到一百个是这样。

还有几十份问卷想扭曲结果，说他们花了大笔的钱在门票上面，这些数字一看就是假的。比如有人写了一千万英磅。最后我拿到一份整理好的结果，可以用每天常用的一般数据分析方法进行分析。我做了所谓的“数据透视表”。我算了一些平均值。诸如此类的分析。

我们最开始也不知道这个项目会有多大规模，所以就是我和体育博客编辑两个人。我们商量了一下，觉得这可能是个有趣的项目。我们做到了，从开始到结束不到24小时。我们想出工作思路，在午餐时间设计好问卷，并把它放在网站上方。接着，问卷受到高度的关注，我们把它在网站上挂了一天，第二天一早结果就发表出来了。

我们之所以决定使用谷歌文档，就是因为它可以完全控制结果。不需要借用其他任何分析工具。我可以很容易的把结果导入数据库软件或者电子表格。如果你开始的时候使用专门的调查软件，通常会受到这些工具的限制。如果问题比较敏感，我们可以会在使用谷歌工具之前慎重思考一下，考虑是否只做“内部”调研。但一般来说，把谷歌问卷挂到《卫报》网页上非常容易，而用户基本上不知道我们在用谷歌来做调研。所以这很方便。

对那些想要使用众包服务的数据记者而言，我的建议是，你必须设计非常具体的问题。而且回答的选择越多越好。对你的调查对象尽量做一些基本的人群信息分析，这样你可以知道你的样本是否存在偏好。如果询问某一事物的数额或者类似的问题，尝试去让大家填写数字，限定使用某一货币单位，等等。这些引导很多可能不会有实际效果，但问卷对民众的引导越多，你得到的结果也会越好。还有一件事，就是记得设计一个评论栏。因为许多人虽然会把问卷填完，但他们真正想做的是让你倾听他们的想法。特别是对消费或者暴力事件的调研项目。

&mdash; _摘自数据新闻博客的 玛丽安·包查特(Marianne Bouchart) 对 卫报西蒙·罗杰斯(Simon Rogers) 的采访_

=== 数据的使用与分享：大纲，细则和现实 

这一章节我们将快速浏览与数据和数据库有关的法规，以及如何利用容易获得的公开式许可和合法工具公布数据。切不要让以下任何状况消磨你对数据新闻的热情。法律对数据的限制既不是你的绊脚石，也无法阻碍别人使用你发布的数据。

不言自明的是，数据的获得并不容易。在数据开放的网络时代之前，即使找到了自己需要的数据集，你还是需要向拥有它的人索取一份副本，可能是纸质，也可能需要你亲自拜访。而现在，获取副本的工作只需通过电脑便能完成。虽然概念上很类似，但是你已经拥有了数据的版权，而那些数据的原创或发布者却什么也没做，甚至不知道你已经下载了一份副本。
 
那么通过程序（俗称``抓数据''）和服务条款(ToS)下载数据时该怎么做？想想前面讲的：你的浏览器就是一个这样的程序。服务条款是否只允许特定程序获得数据？如果你有大量的时间和金钱，当然可以选择去阅读此类文件或者咨询律师。但在通常情况下，不要表现得素质低下——如果你的程序攻击了别人的网站，你会被该网站屏蔽，咎由自取。如今网络上有大量访问数据和抓数据的行为，如果你计划这么做，研究一下诸如ScraperWiki等网站上的例子会是个不错的开始。
 
一旦你拥有了感兴趣的数据，便可以查询、钻研、分类、视觉化，利用数据副本进行相关性或任何其他类型的分析。你还可以发布引用了其中任何数据的分析。在言论自由的情况下，｀｀事实是免费的''这个标语言符其实。但对于需要考虑很多合法性问题、甚至是掌控数据层面的人来说，这可能只是一个标语而已。

身为一个优秀的或渴望优秀的数据新闻从业者，如果你想要发布的不只是包含事实和数据的分析，还有在分析过程中援引的其他数据，应该怎么做呢？当然，你可能只是正在监护数据，还并没有进行任何分析——这点很好，因为这个世界需要数据监护。如果你打算使用其他实体收集来的数据，也许会遇到意外的麻烦。（如果你亲自组建了数据库，那就阅读下一段，当作看下下段“数据分享”的动力吧！）

如果熟悉版权对创意作品的限制使用，你会知道，当版权所有者未对某作品授权（除非你的作品属于公共领域，或你在例外允许的情况下使用，或符合“合理使用”的范围），版权所有者可以强迫你停止使用和发布其作品。尽管事实是免费的，即使与其相关的法律比创意作品版权的法律有着更多的变化，事实收集却很相似地被限制 。简而言之，数据可以作为创意作品受版权制约。在很多司法管辖区内，仅凭``辛勤搜集原则(sweat of the brow)''组建一个数据库，即使用毫无原创性的方式，也可以获得版权。尤其在美国，有更高的“最低原创性”标准（可以参考费斯特出版公司有关电话薄版权纠纷的经典案例）。但在某些地区，也存在着从版权中分离出来用以规范数据的“数据权”（两者实则有很多交集，特别是在版权的获得几乎不需要原创性的时候）。其中最知名的就是欧盟对数据库的“特殊权利保护”（拉丁语sui generis），如果你在欧盟国家发布来自其他实体的数据，一定要确认是否拥有相关许可。

这些限制显然不是培养数据新闻生态系统的最好方式，对社会普遍来说也没有好处（在“特殊保护权利”制定之前，社会科学家曾警告欧盟这一点，之后也被研究证实是正确的）。幸运的是，作为数据库的发布者，你可以通过事先准许将这些限制移除（假使其中不包含你无权进一步授权的部分）。你可以通过公开式许可或贡献给公共领域而发布数据——像许多程序员通过免费和开放资源许可发布代码一样，这样别人就可以直接取用（数据新闻不仅是数据，也包含代码；发布数据的同时也要发布代码，这样你的数据和分析才有再生价值）。公开数据有太多好处——比如，受众可以利用你的数据创造新的视觉化或应用方式并与你建立链接，就像英国卫报在Flickr上建立的数据视觉化群组；此外，你的数据还可以和其他数据结合起来，令你和读者更深入了解一个话题；别人利用你的数据做的事可能引导你发现新故事以及新故事或其他数据项目的构思。这些做法必会给你带来声誉。

[[FIG0415]]
.开放数据预算 (Open Knowledge Foundation)
image::figs/incoming/04-GG.jpg[float="none"]

当你意识到在公共许可下发布数据是必需的，问题就变成了——哪个许可？能回答这个棘手问题的，一般是你在作品中借鉴过数据和分析的项目或组织，或者你想要将作品贡献给的人或组织——简而言之，沿用它们的许可。如果你想要走得更远，那就从免费和公开的许可组合开始，意味着任何人都拥有被用于任何用途的许可（可能要求署名和相同方式分享）。像Free Software Definition（自由软件定义）和Open Source Definition（自由资源定义）之于软件，http://opendefinition.org/[Open Knowledge Definition]（开放知识定义）被用于包括数据在内的任何其他知识资源，用以定义自由作品的属性和开放式许可允许用户做的事。
 
你可以前去开放知识定义的网站查阅符合http://opendefinition.org/licenses/[一系列被认定的许可]。总结来看，基本上有三个等级的公开式许可：

贡献给公共领域::
  也称最大化许可——使用其作品无需任何条件.

仅在许可或署名情况下发布::
  对作品进行署名是唯一实际条件.

对称版权、互惠或相同方式共享许可::
  要求发布被修改作品时使用与原作品相同的许可。


如果你在公开式许可下使用别人发布的数据，可以把以上几点当作如何满足公共式许可条件的简要指南。你可能遇到的从Creative Commons到Open Data Commons和各级政府机构的大多数许可，都会用大纲的形式让你更容易地了解到这些实际条件。通常情况这些许可会在下载数据（或者``抓数据'',理所应当的，网页里也包含数据集）的网页上显示，或者在数据文件里的显眼位置，形式不同而已。在你公开自己的数据时，也要如此标示。

回到最初的问题，万一你需要的数据无法通过网络获得，或者受制于某种访问控制？你可以考虑，除了为自己争取访问权利之外，也要争取这些数据对全世界公开以得到再利用。你可以指点他们，一旦数据被公开，将会有怎样伟大的事情发生。

与世界分享可能会令你想到，对于某些数据而言，隐私、其他方面的考虑和规范可能将发挥作用。的确，仅仅因为公开的数据降低了很多技术、版权和版权相关的门槛，并不意味着你不需要遵守其他适用的法律。但这些情况古而有之。当你出于常理驱动去做一项研究时候，你会发现新闻从业者拥有庞大资源，以及不时存在的保护措施。

祝你好运！但是相比于控制（并不高的）法律风险，你更需要补充关于数据新闻项目中其他方面的知识与技能。


&mdash; _麦克·林克斯维耶(Mike Linksvayer)，Creative Commons_

