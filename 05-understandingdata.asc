:chapnum: 05
:figure-number: 00

[[understanding_data]]
== 理解数据

image::figs/incoming/05-00-cover.png[float="none",role="informal"]

++++
<?dbfo-need height="1in"?>
++++

一旦你有了数据，那你应该对这些数据做什么呢？你应当寻找什么？你应该使用哪些工具？这一部分以一些能提高你数据素养的意见，处理数字和统计的小提醒，以及在处理复杂棘手，经常有缺失数据时候需要牢牢记住的东西开始，接着讲述学习如何从数据中讲故事，数据新闻记者对工具的选择还有如何使用数据可视化提供你关心话题的洞察。

=== 简单三步让自己变的有数据素养

正如文字素养着重于``通过阅读获取知识，能条理写作，并可以批判性分析书面材料的能力''，数据素养是一种消化数据获取知识、梳理并批判性分析数据的能力。数据素养不仅包括统计素养，更需要懂得如何处理庞大的数据集，明白这些数据集是怎样产生的，知道怎样把各种数据集联系起来，且懂得解释它们。

[[FIG051]]
.http://www.flickr.com/photos/jdhancock/3386035827/[深入挖掘数据] (JDHancock 摄)
image::figs/incoming/05-MM.jpg[float="none"]

++++
<?dbfo-need height="1in"?>
++++

波音特新闻大学(Poynter's News University)开设了针对http://www.newsu.org/courses/math-journalists[新闻工作者的数学课程]，帮助他们去理解诸如比例变化和平均数等概念。有趣的是，与此同时，在距离波特因学院不远的佛罗里达州的小学里也面向5年级的学生（10-11岁的孩子）开设涵盖同样知识的http://bit.ly/k12-courses[课程作为必修课]。

这些新闻从业者急需的数学知识竟然来自高中之前的课程，可见如今新闻编辑部的数据素养有多欠缺。这是个大问题。如果一个数据新闻从业者连什么是“置信区间”都不知道，怎么去利用全球气候变化的系列数据呢？如果一个数据新闻记者连http://bit.ly/karenberger-mean-median[中位数和平均数都无法区分]，怎么写关于收入分配的报道？

当然，一个记者不需要为了更高效率地处理数据而去专门拿一个统计学的学位。不过，如果掌握一些数据处理的小技巧，那么，他们面对数字的时候会从中挖掘出更有价值的信息来，进而写出更为出色的报道。正如马克思·普朗克学院教授http://bit.ly/ddjnet-numeracy[杰德·吉仁泽所说](Gerd Gigerenzer)，如果缺少洞察，那么再好的数据处理工具也无助于新闻质量的提升。

所以，接下来，你只需要问三个简单的问题，即使你在数学或者统计学知识方面有所欠缺你也可以成为一名老练的数据记者。

==== 1. 数据是怎么被收集的？

===== 惊人的GDP增长

伪造数据是利用重大数据出风头的捷径。这听起来毫不稀奇，但正如GDP数据通常被人们评论的那样，数据很可能是假的。前英国大使卡瑞吉·默里在其著作http://amzn.to/murder-samarkand[《撒马尔罕城谋杀》]中称，乌兹别克斯坦的经济增长率受制于地方政府和国际经济体之间的紧张谈判。换句话说，它与地方经济没有任何关系。

GDP被作为首要经济发展情况参考指标，是因为政府需要用它来监控自己的主要收入来源——增值税。一旦当一个政府不靠增值税提供资金，或当它不公布财政预算时，就没有采集GDP数据的理由了，并且通过伪造GDP数据，国家会看起来富足繁荣。

===== 犯罪率永远在增加

http://bit.ly/elpais-numeracy[《国度报》报道称]，``西班牙的犯罪率上升了3%。''http://bit.ly/rtl-numeracy[RTL电视台说]，布鲁塞尔正在打击非法侨民和吸毒者犯罪。这类基于警方统计资料的报道很常见，但关于犯罪的更多情况，它没有反映出来。

我们可以相信，在欧盟内部，数据没有被篡改。但警方应对犯罪发生的诱因做出更多回应。比如，当工作业绩与打击犯罪率挂钩时，警察就被鼓励尽可能多地汇报不需要调查的犯罪事件。这类罪行之一就是吸毒。从而，这就解释了为什么在法国与毒品相关的犯罪在过去15年中翻了四倍，但毒品消耗量却不变。

===== 你能做些什么？

当怀疑一个数字的可信度时，往往要进行反复检查，就像你寻找数据时那样——就算它引用自官方。在乌兹别克事件中，给在当地居民打个电话就完全足以证实数据的可信性了（“问问该国是不是像官方数字显示的（那样），（感觉像是）比1995年时富裕了3倍”）。

针对警方数据的可信性，社会学家常常会进行受害者研究。在这个过程中，他们会询问人们是否遭遇犯罪事件，以此来验证警方数据的真实度。这些研究所得数据要比警方数据更平稳。因此，也许这就是它们上不了头条新闻的原因。

虽然其他检验方法可以让你准确评估数据的可靠性，比如本福德法则(Benford's law)，但最重要和有效的方法还是你自己的批判性思考。

==== 2. 我们应该从中学到什么？

===== 夜里工作会使多发性硬化症的风险加倍

相信一些理智的德国人在读了本篇新闻http://bit.ly/dmsg-numeracy[这个标题]后都会停止在夜里工作。但这篇文章最后并没有告诉我们真实的风险是什么。

1000个德国人中，只有一个会在有生之年患上多发性硬化症。假设现在，如果这1000个德国人都上夜班，那么多发性硬化症患者的数量将上升到2个。因为上班时间改变而增加的患多发性硬化症的风险是1/1000，不是100%。所以，当你在考虑是否接受一份工作时这个信息或许更有用。

===== 平均15个欧洲人里就有一个是彻底的文盲

上面的标题看起来很唬人，但是它也绝对是真实的。在50亿欧洲人中，有3,600万可能都不识字。但是，即使文盲数量达到3600万，其比例也仍然低于7%（数据来自http://bit.ly/eurostat-numeracy[欧洲统计局]）。

在采用平均值的时候，要时刻思考``是什么的平均值？'' 涉及的基数是同质的吗？例如，非均匀分布的样本就解释了为什么大多数人的驾驶水平都高于平均值。很多人一生都没有或仅出过一次事故。但是，几个鲁莽的司机制造了大量事故，就会推高事故的平均值，使其高于大多数人的经历。对于收入分配也是同样的道理：即，大多数人的收入低于平均值。

===== 你能做些什么

随时注意数据分布和基数比率。通过检验其平均值和中位值，以及靠众数（分布中最常见的数值），来进行数据洞察分析。就像在多发性硬化症报道的例子中，分辨出哪种数据更重要，就能更容易地配合主题合理运用数据。最后可知，从本盏率的角度进行报道（1000个中有1个）比用百分比（1%）更易于读者理解。

==== 3. 信息有多可靠？

===== 样本量的问题

由http://bit.ly/diariodenavarra[萨拉戈萨出资的<Diaro de Navarra>]公布的一份调查称``80%的人对司法系统不满意。''仅仅从4.6千万西班牙人中找了800名受访者进行调查，怎么能做出这一推断？这一数据明显被夸大了。

在对大量人口进行研究时（数以千计），要控制误差率低于3%，只需要不到1000的抽样人口。这意味着，如果你找完全不同的样本重新调查，10次中有9次，你得到的结果和你最初得到的结果之间的误差不会超过3%。统计学是很有用的东西，而且在狡猾的调查中，抽样出来的样本量几乎不会受到质询。

===== 喝茶能降低中风的风险

关于喝茶益处的文章司空见惯。《德国世界报》上的http://bit.ly/welt-tea[这篇短文]称，茶叶能完全地降低心肌梗塞风险。虽然一些人认真研究茶叶的功效，但很多研究没有考虑到生活方式的因素，例如减肥、消遣或运动。

在大多数国家，茶是有保健意识的上层人的饮料。如果研究者不能在对茶的研究中考虑进生活方式的因素，那么他们能告诉我们的就只是“富人更健康，原因可能是他们很可能喝了茶”。

===== 你能做些什么

在有关茶的报道案例中，在很多情况下，相关性和误差背后的数学规律同样适用。但如果研究者不寻找相互关联的因素（例如喝茶与做运动的联系），他们的研究结果将毫无价值。

作为一名新闻工作者，去挑战一项研究的数值例如样本量的结果毫无意义，除非严重怀疑数据的可信性。但是，观察研究者是否考虑了相关信息则很容易做到的。

&mdash; _尼古拉斯·凯瑟－布瑞尔（Nicolas Kayser-Bril），Journalism++_

=== 新闻中的数字运用技巧

* 处理数据的最佳技巧就是让自己乐在其中。数据看起来令人生畏，但如果被它吓住，你将一无所获。如果像做游戏和探险一样对待它，那么，它将变得格外容易地透露秘密和真相。所以，就像你处理其它证据一样简单地处理它吧，不用害怕也不用另眼相看，甚至可以将之当成一次想象力训练。在选择报道角度时，不妨更具创造性一点，使之能更符合数据、更好地解读数据，然后再用更多论据去印证它。“其它报道会怎样解读？”是个简便的参考方法，帮助你思考这个数字——这个明显偏大或不正常的数字、明显反映出这种或那种状态的证据，怎么会被解读出截然不同的结果。

* 不要把对数据的质疑和轻视搞混淆。质疑是好的，轻视却是粗暴地放弃数据。如果你相信数据新闻，不管你是否阅读本书，你都必须相信，数据能提供的东西，远远好于那些讽刺文章中的谎言和胡言乱语，以及倾向性报道中经过筛选，意图诋毁某人的客观事实。如果好好利用，数据常常能带给我们深刻的认识。所以，我们在运用它时既不能轻视也不能轻信，而需要慎重。

* 如果我告诉你经济衰退时饮酒率上升，你可能会说那是因为人人都心情低落；可如果我告诉你饮酒率下降，你可能会说那是因为人人都经济窘迫。换句话说，数据说什么，不影响你已经认定了的理由（诠释），也就是说，你通过不同方式，总可以证明情况很糟糕。这里要提出的观点是，如果你相信数据有用，试着在你凭着情绪、信仰和预期展开辩论前，先让它说话。数据那么多，只要你随便找一找，基本都能发现足以印证你之前观点的证据。换句话说，如果你不够虚心，至少在我看来，数据新闻对你的帮助不大。你想做的只是达到你的目的，而非解读出基于数字（之）上的事件本质。

* 数据新闻的结论不确定是正常的。因为，我们习惯于将数据看作权威的和确定的，但事实常常并非如此。答案是没有答案，或者答案是我们能得到的最好的但仍不能保证绝对正确的。我想我们应该面对这些事实。如果你认为它听起来像是毁掉报道的好方法，那我要告诉你，其实它恰恰是一个发现新问题的好方法。同样的，常常有多种裁剪数据的合理方法。数字并不是只有对或错两种情况。

* 调查过程就是一篇报道。在你逐个寻找证据时，你如何努力发掘真相的经历就能做一篇好新闻——这种寻找肯定有助于从数据中获取证据，因为仅仅一个数字几乎不能形成证据。不同的消息源能提供全新的角度、全新的构想，更多元的理解。我想我们是太急于成为权威并告诉人们答案了——所以，我们因为没有公布调查过程而失去了一个做出好新闻的诀窍。

++++
<?dbfo-need height="1in"?>
++++

* 最好的问题还是老问题：这个数字真的重要吗？从哪里能够获得？你确定它真的如你认为的一样有价值？这些通常只是提醒你全盘考虑数据，只看单个数字会使眼光狭隘。现实生活环境、将数据作纵向对比时覆盖的时间长度、数据的分类和结构...简而言之，所有关于数据的背景，都要考虑。

&mdash; _迈克尔·布拉斯兰(Michael Blastland)，自由记者_

=== 处理数据的基本步骤

在对数据进行处理之前，你至少需要知道以下三个关键点::

* 数据需求的提出取决于你想要解决的问题。

* 数据通常是不规范的，在使用之前需要进行清洗。

* 数据可能包含未记录的内容。

下文将详细展开这三点：

[[FIG052]]
.杂乱的数据
image::figs/incoming/05-MM.png[scale="89",float="none"]

==== 了解你想弄清楚的问题

在很多时候，与数据打交道跟采访（现场）信息源一样，你需要通过挖掘跟数据相关的问题来揭示答案。但正如同信息源只能告知其掌握的相关信息，数据也只有在被正确地记录、拥有恰当变量的情况下才能回答你提出的问题。这意味着，在获取数据之前你就需要仔细考虑清楚你想要通过数据来回答什么问题。因此，通常你的数据处理工作是回溯性的。首先，列出你想在报道中通过数据来证明的论点。然后，为了证明这些论述，确定该获取、分析哪些变量和数据记录。

以当地犯罪报道为例子。比方说，你想写一篇揭示所在城市犯罪模式的报道，那么就会涉及到在一天中的哪个时段，或者是在一周中哪几天最容易发生犯罪行为；又或者，哪些地方是各种犯罪行为的“热点”区域。

那么，你会意识到，你需要的数据包括（报导中每次）犯罪的日期和时间、犯罪的类型（杀人，盗窃，爆窃等）以及犯罪发生的地点。因此，为了回答你所提出的问题，你至少需要日期、时间、犯罪类型和地点这四个变量。

不过，需要注意的是，如果数据集只包括这四个变量，一些潜在的有趣问题就_无法_得到回答。比如说，受害者的性别与种族、被盗窃财产的总价值，以及哪位警官逮捕罪犯最卓有成效等。此外，你获得的相关数据记录可能只涵盖一段时间，比如说过去三年。这意味着你没法说明犯罪模式在一个更长的时间段里是否发生了变化。这些问题可能并不在你原本的报道计划当中，那么，这就没有问题。但是，你一定不会希望当你一股脑扎进数据分析之后，突然决定要知道这些不在计划当中的数据，例如，在不同的地区，犯罪分子被绳之于法的比例是多少的情况发生的。

这里的经验教训是，数据需求应当是包括数据库中所有变量和记录的_完整_数据，而不是为了解决当下报道中需要回答的问题而获取的子数据集。（事实上，如果你需要花钱来获得所需要的数据，那么获取完整数据往往比只要一个子数据集便宜。）你可以随时从数据中截取需要的那部分，而获得完整的数据后，还可以帮助你回答报导中可能遇到的新问题；你甚至还可能从中为后续报道找到新点子。虽然，某些信息，比如受害人的身份或是秘密线人的姓名，可能会因为保密法或者其他法规而无法公开。但在报道当中即使是部分的数据呈现也远远比没有好，只要你明白哪些问题是通过数据分析可以回答的，而哪些不能。

==== 清洗数据

数据库工作中最大问题之一是，你需要将基于官僚管理需要而收集的数据拿来做分析使用，可问题是，这两类数据的精确标准大不一样。

例如，犯罪司法系统数据库的一个重要的作用是轮到被告人琼斯被听证的时候，确保他能够从监狱里被带到法官史密斯面前。出于此目的，琼斯的出生日期是否准确、住址的街道名称有没有拼写错误，甚至他的中间名缩写有误，真的一点都不重要。一般情况下，该系统仍能用这份不完美记录在指定时间把琼斯带到史密斯的法庭上。

但是，这些错误会严重影响记者试图通过数据库来发现当地犯罪模式而所做的努力。基于这个原因，当你获得一个新数据库时，首要任务是确定它到底有多凌乱，然后把它清理干净。一个有效快速的方法可以找到错误数据：创建统计绝对变量的频次表，绝对变量即那些预计变值会相对较少的变量。（如果是用Excel，你可以通过在每个绝对变量上使用筛选或者透视表来实现）。

用``性别''来举个简单例子。你会发现，你的性别栏中有各种数据值：男性、女性、男、女、1、0、男人、女人等等，甚至还有诸如“Femal”这样的错误拼写。为了做一个合理的性别分析，你需要制订一个标准——比如说用M和F来分别表示男性和女性——然后改写所有的不同写法以符合该标准。另一个常常会碰到这类问题的数据库是美国竞选财务记录。在这个数据库中，职业一栏中，（比如律师这一职业）会有诸如``Lawyer、''``Attorney、''``Atty、''``Counsel、''``Trial Lawyer''等多种多样的写法以及拼写错误。同样的，解决问题的诀窍是规范职业称呼，避免过多的变化。

处理名字的时候，数据清理的工作变得更加棘手。``约瑟夫·T·史密斯''、``约瑟·史密斯''、``J.T.·史密斯''、``约什·史密斯''是同一个人吗？这时候需要查看其它的变量，比如说地址或是出生日期。有时候甚至需要仔细研究别的数据记录才能够确定。通过使用类似于Google Refine这样的工具可以让清理和标准化的工作更加快捷，不那么劳累。

.Dirty Data
****
Thanks to the generally strong public records laws in the United States, getting data here isn't as big a problem as it can be in many other countries. But once we get it, we still face the problems of working with data that has been gathered for bureaucratic reasons, not for analytic reasons. The data often is ``dirty,'' with values that aren't standardized. Several times I have received data that doesn't match up to the supposed file layout and data dictionary that accompanies it. Some agencies will insist on giving you the data in awkward formats like .pdf, which have to be converted. Problems like these make you appreciate it when you do get an occasional no-hassle dataset.

&mdash; _Steve Doig, Walter Cronkite School of Journalism, Arizona State University_
****

==== 数据可能包含未记录的内容

任何数据库的“罗塞塔石碑”就是所谓的数据字典。一般而言，这个文件（通常是text或者PDF甚至是电子表格）会告诉你这个数据的格式（delimited text、fixed width text、Excel、dBase等），变量的顺序、各个变量的名字以及各个变量的数据类型（文本字符串、整形、浮点等）。你可以利用这些信息帮助你把数据文件恰当地将导入到你想使用的分析软件中（Excel、Access、SPSS、Fusion Tables、各种SQL等）。

数据字典中还有另一个关键元素——解释特定变量的信息使用的代码。例如，性别可能被编码，使“1 =男“和”0 =女“。罪犯们的罪行种类可能会以司法管辖区的法规号码来代替。医院治疗记录可能会用数以百计的五位数代码中任何一个来表示对受诊病人的诊断。没有数据字典，这些数据集很难、甚至不可能被正确地分析。

但是，即使数据字典在手，还是会出现问题。一个例子是，若干年前佛罗里达州的《迈阿密先驱报》记者分析因酒醉被捕的人们受到的判罚如何因不同的法官而发生变化。记者从法院系统获得定罪纪录，并根据数据字典分析了三个不同的处罚变量的数据：监禁时常（时长）、拘留时常（时长）和罚款金额。这三个数据会因法官的不同而有所变化。记者以此为证据，写了篇关于有些法官判罚严厉、有判罚些温和的报道。

但每一位法官都有约1-2％的判决数据没有显示监禁时间、拘留时间和罚款金额。因此，在展现（展示）不同（每个）法官的判决模式的图表中，都有一小部分案子显示“没有惩罚（零处罚）”，（即使在复审时）。当新闻报道和图表出现在报纸上后，法官们厉声抱怨《迈哈密先驱报》是在控告（控诉）他们违反州法律，因为根据州法律，任何人酒后驾驶都要受到惩罚。

因此，记者又回到了生产（制作）这些数据文件的法院办公室（书记员那里），询问是什么造成了这个错误。他们被告知，这些（被质疑的）案件涉及的是首次被捕而经济窘迫的被告。一般情况下，他们会被要求支付罚款，但他们没钱。所以法官判罚他们去进行社区服务，比如说清理街道上的垃圾。由此导致的结果是，数据库结构创建完成后，这些法律要求的惩罚被忽略了。因此，每一位书记员都知道，在数据中，监禁、拘留、罚款都显示空白就意味着社区服务。然而，这_并没有_在数据字典中被标注出来，并因此造成《迈哈密先驱报》发布撰写（更正）启事。

在这种情况下（这件事）的教训是，要向给你数据的工作人员（机构）咨询，数据中是否有未记录的数据（元素），无论它是新近创建、还未被收录入数据字典的代号（代码），还是文件布局改变（编排的改动），亦或者是别的什么东西。此外，不要忘记检查你的分析结果，并问：“这有意义（讲得通）吗？”《迈哈密先驱报》的记者绘制图表已经临近截稿时间，并且他们过于专注在每名法官的平均判罚水平，没有注意到那些看上去“没有收到惩罚（零处罚）”的（容易忽略的）少数案件。他们应该问自己，如果真是如此，所有的法官（看起来）都违反了州法律（是否讲得通），哪怕仅仅是在很小的程度上。

&mdash; _史蒂夫·多伊格（Steve Doig），沃尔特·克朗凯特新闻学院，亚利桑那州立大学_

++++
<?dbfo-need height="2in"?>
++++

.Mixed Up, Hidden and Absent Data
****
I remember a funny situation where we tried to access the Hungarian data on EU farm subsidies: it was all there--but in an excessively heavy PDF document and mixed up with data on national farm subsidies. Our programmers had to work for _hours_ before the data was useful.

We also had a pretty interesting time with data about EU fish subsidies, which national payment agencies in all 27 Member States are obliged to disclose. Here's an excerpt from http://bit.ly/alfter-eu27[a report we wrote on the topic]: ``In the United Kingdom, for example, the format of the data varies from very user-friendly HTML search pages to PDF overviews or even lists of recipients in varying formats hidden away at the bottom of press releases. All this is within just one member state. In Germany and Bulgaria, meanwhile, empty lists are published. The appropriate headings are there but without any data.''

&mdash; _Brigitte Alfter, Journalismfund.eu_
****


=== 32英镑的一条面包

这是一篇周日威尔士地区报道的有关威尔士政府在无麸产品配方上的花费的新闻稿。http://bit.ly/walesonline-gluten-free[大标题中标明]一块面包需要花费32英镑。但是，实际情况却是11块面包，每块2.82英镑。

这个数字来源于威尔士议会的书面答复，以及威尔士地区国民健康保障体系（NHS）发布的有关每一配方所花费的款项。但是，却没在数据字典里额外列明每个配方的的定义和在数量栏的每一项统计单位如何界定。

因此，就导致人们理所当然的假设这针对的是每个个体，即是，一块面包的花费，而不是事实上一个包装的好几块面包费用。

没有一个人，无论就这个数据书面回复者还是发布新闻的官员，都没有发现这个问题，直到这则报道在星期一刊发出来，大家才发现了数量上的问题。

所以，这个事件告诉我们，不能想当然地认为政府发布的数据中那些说明背景信息的注释能有效地把数据解释清楚，或一厢情愿相信负责数据的官员会意识到数据表述不够清晰，即便你已经把自己错误的数据解读传达给对方。

众所周知，报纸都追求报道的标题可以抓人眼球，除非显而易见存在无法解释得通的情况下。否则这些能够吸引人眼球的报道标题都很容易通过，没人会太仔细的去检查核实，特别在临近截止日期时还要冒着报道被砍掉的风险。

[[FIG053]]
.无麸质面包法令花销威尔士纳税人32英镑 (威尔士在线 WalesOnline)
image::figs/incoming/05-AA.png[float="none"]

但是，即使可能导致新闻报道被砍掉，记者也有责任去核查那些荒谬的论断。

&mdash; _克莱尔·米勒(Claire Miller)，威尔士在线(WalesOnline)_

=== 从数据开始，以故事结尾

为了吸引读者，你得用标题中的数字让读者打起精神并引起他们的注意；即便是不知道背后的数据集，你也应当可以阅读故事；要让故事激动人心，并时刻牢记哪些人是你的读者。

其中一个例子是，新闻调查局(Bureau of Investigative Journalism)实施的一个项目中，使用了欧盟委员会的http://bit.ly/ec-fts[财务公开系统]。那么这个报道也正是来源自我们最初想在数据库中查询的一些数据。

我们利用诸如“鸡尾酒”、“高尔夫”和“假期”等关键词搜索数据。这让我们确定了委员会在这些项目上的花费，并让随后我们提出大量的问题并作报道。

但是通过关键词不是每次都能找到你要的，有时你得坐定思考你真正寻求的东西。项目进行过程中，我们还想得知委员们在私人（喷气式）飞机旅行上的花费，但数据里没有“私人喷气式飞机”这个条目，我们不得不靠其他方法得知他们旅行供应商的名字。一旦我们知道为委员会提供服务的供应商名字叫“Abelag”，我们就能通过查询数据得知由Abelag提供的服务开销是多少了。

通过这个方法，我们在查询数据时就有了定义确切的对象；找到能够支撑标题的数字，以及整个的基调。

另一种方法是从黑名单着手，查找额外项目。从数据中找到故事的简单办法就是知道有哪些东西是数据库中不应该有的。《金融时报》与新闻调查局联合的欧盟结构基金项目对此作出了很好的说明。

委员会自己制定了规则，规定了哪种类型的公司和协会应当被禁止领取结构基金（译者按：Structural Fund，欧盟设立旨在支持落后地区或产业衰退地区的经济发展与产业结构调整的调控基金）。对香烟和烟草生产商的开支是其中一个例子。

以烟草公司、生产商和种植商的名字来查询数据，我们找到数据显示英美烟草集团处于德国的一家工厂接收了150万欧元，这笔资金违反了委员会关于开支的规定——这是从数据中找到故事的快捷办法。

你永远不会知道自己将在数据集里得到什么讯息，所以尽管来看一眼。你需要多一点野心，当你使用筛选工具（最大、极端、最普遍，等等）来确定一些明显的特征时，往往就能有所斩获。

&mdash; _克莱恩·巴(Caelainn Barr)，Citywire_

=== 用数字说话

数据新闻有时会给人一个印象，即它主要是关于数据展现的。比如数据可视化，迅速而又强大地传达对一堆数字某一方面的理解；再比如可搜索的交互式数据库，任何人都可以在里面查询比方说自己当地的街道或者医院信息等。所有这些都非常有价值，但是跟其他类型的新闻一样，数据新闻也应当是一个个的故事。那么你能在浩瀚的数据中发掘哪些故事呢？基于我在BBC的从业经历，我写了如下一个列表，或者说是各种不同类型数据故事的“类别模型”吧。

不管你是在分析数据，还是处于搜集数据这前一阶段（无论是寻找公开数据还是发起信息自由申请），我认为牢牢记住下面列出的这些信息都是很有帮助的。

测量::
  最精简的新闻故事；计数与求和: “去年，全国各地的地方议会总共在采购回形针上花了X万亿英镑。” 但通常这样一个笼统的数字很难让人明白到底是花多了还是花少了。因此，你得把数字放进特定的语境中——比如，可以运用：

 比例;;
 “去年，全国的地方议会在回形针上的支出占到全部文具预算的三分之二。”

国内比较;;
  “地方议会在回形针上的支出多过为空巢老人送餐到家服务上的支出。”

海外比较;;
  “去年，议会在回形针上的支出是国家海外救援预算的两倍。”

当然在特定语境下或者用比较的方法来探索数据还有其他各种各样的方式。

随时间变化::
  “四年来，议会在回形针上的开销增长了两倍。”

“排名表”::
  因为通常会有地域或惯例上的差异，所以你得确保用来做比较的基础是公平的（即要把当地人口规模的考虑进去）。“Borsetshire议会的工作人员在回形针上的人均花销要高于其他地方议会。前者的数值是全国平均水平的四倍。”

或者你可以把整个数据分成几组:

分类分析法::
  “紫党政务委员会用于购买纸夹的开销比黄党的多出50%。”

或者你可以用数字把各个因素联系在一起:

关联比较法::
  ”接受过文具用品公司捐款的那些政务委员会用在纸夹的开销更大，平均每一英磅的捐款，开销增长100英镑。“

当然，你要记住，相关性和因果关系不是一回事。

++++
<?dbfo-need height="1in"?>
++++

因此，如果是在调查购买纸夹的开销，你是不是也获得了以下的数据？

  * 能提供语境的总支出是多少？
  * 能作为参照的各地区数据、历史记录和其他的统计数据？
  * 辅助性的数据，比如人口参数？这能保证对比的公平。
  * 其他的数据？有意思的、有联系的数据可拿来与此项开销进行对比。

&mdash; _马丁·罗森鲍姆(Martin Rosenbaum)，BBC_

=== 数据记者对工具选择的讨论 ===

噗嘶嘶嘶…这是你的数据从压缩包里解压的声音。现在怎么办？你想要从数据里寻找到什么？ 准备用什么数据处理工具？对此，我们询问了一些数据新闻记者，看他们是如何处理数据的。以下是他们的经历…

[quote, 丽莎·埃文斯(Lisa Evans), 卫报]
____
《卫报》的数据博客非常看重与读者互动，这使读者能够在我们的基础上，快速复制《卫报》的数据新闻报道，并且发现一些我们没有发现的东西。因此，越直观的数据处理工具就越好。我们尽量挑选任何人都不用学习编程语言或经过特殊训练就能掌握、并没有高额附加费用的数据处理工具。

基于这个原因，目前我们大量使用谷歌的有关数据处理的产品。我们整理和发布的所有数据集都可以通过谷歌电子表格呈现，这意味着任何有谷歌帐户的人都可以下载数据，导入到自己的帐户，制作自己的图表，对数据进行排序，并创建数据透视表，也可以将数据导入到他们所选择的工具里。

我们使用谷歌的融合表(Google Fusion tables)来组织数据。当我们在融合表中创建热力图时，也将我们的KML文件分享到网站上，这样读者可以下载并建立自己的热力图，包括在数据博客的原始图上加入新的数据层。这些谷歌工具还有一个不错的功能是，他们适用于读者访问博客的不同终端，比如台式电脑、手机和平板电脑。 

除了谷歌电子表格和融合表，我们在日常工作中还使用了其他两个工具。一是tableau，一个多维数据集可视化的工具，二是ManyEyes，用来对数据进行快速分析的工具。不过，这些工具都不够完美，所以我们将继续寻找让读者喜欢的更好的可视化工具。
____

[quote, 辛西娅·奥墨楚(Cynthia O'Murchu), 金融时报]
____
我会变成一个程序员吗？不太可能！我当然不认为每一位的记者都需要知道如何编程。但我认为具有对可能性更为普遍的认知，并知道如何跟程序员对话，是非常有帮助的。

如果你开始了，先学走路别急着跑。你需要说服你的同事和编辑，使用数据可以让你们得到其他方法得不到且值得去做的报道。一旦他们看到了这种方法的价值，你就可以向更复杂的报道和项目进军了。

我的建议是先学习Excel然后用它做一些简单的报道。从小处着手逐渐到数据库分析及数据制图。你可以在Excel中做很多事情——它是一个及其强大的工具，但大多数人对Excel功能的使用却是那么可怜兮兮。如果可以的话，参加一个为记者开设的Excel课程，比如新闻调查中心提供的课程。

带着敬畏之心去解读数据，不要轻视它。你必须要认真，要注重细节并且质疑你得出的结果。你需要保留处理数据的记录和原始数据的副本，因为在处理数据时候是很容易犯错误的。我经常要几乎从头到尾反复做两到三次分析来进行检查和验证。如果能让你的编辑或其他人分别分析数据并比较彼此的结果就更好了。
____

[quote, 斯科特·克雷恩(Scott Klein), ProPublica]
____
像记者撰写一个新闻报道那样一边快速写作，一边使用复杂的数据处理软件是一件相当了不起的事情。这在过去要花很长的时间。好在得益于在二十一世纪头十年的中期首次发布的Django和Ruby on Rails，这两个免费/开源的快速开发框架的出现，事情发生了变化。

Django是基于Python编程语言开发的，由阿德里安·霍洛瓦季和他位于堪萨斯州劳伦斯的劳伦斯日报世界版编辑部团队开发的。Ruby on Rails是由大卫·海涅迈尔·汉森和一个网络应用程序公司37Signals，在芝加哥开发的。

虽然这两个框架采取不同的方法来实现``MVC模式''，但它们都很出色，能快速地建立即使是非常复杂的网络应用程序。他们可以完成建立一个应用程序的基本工作。比如创建并从数据库中获取项目、将URL与应用中特定的代码匹配。这些都被写进了程序的框架里，使开发人员并不需要编写代码来做这些基本的东西。

虽然一直没有对美国新闻app团队的正式调查，但通常大多数团队都使用这两个框架之一作为数据库支持的新闻应用。在ProPublica（一个非盈利调查机构）我们使用的就是Ruby on Rails。 

提供像亚马逊网络服务这样的快速网络服务器``切片''的发展，同样给过去开发一个应用缓慢的过程带来改观。 

此外，我们有很标准的工具去处理数据：用Google Refine和Microsoft Excel清理数据；用SPSS和R做统计; 用ArcGIS和QGIS去做GIS；用Git做源代码管理；用TextMate、VIM和Sublime Text写代码；用MySQL、PostgreSQL和SQL Server的组合做数据库。我们建立了我们自己的JavaScript框架，``Glass''，来帮助我们快速建立在JavaScript前端的大量应用。 
____

[quote, 谢丽尔·菲利普斯(Cheryl Phillips), 西雅图时报]
____
有时最好的工具就是最简单的工具——电子表格就是一种简便而又力量强大，却常常被我们被低估的工具。当所有东西都存储在DOS系统下的时候，通过使用电子表格，我能够理解得克萨斯巡警棒球队股东们合伙协议中的复杂公式——而时逢乔治·W·布什恰是主要股东之一。电子表格可以帮助我标出异常值或计算错误。由此，我可以撰写出框架脉络或者更多的东西。

而这是数据记者“工具箱”里的基本装备。也就是说，我最喜爱的工具拥有更强大的功能——用SPSS做统计分析和地图程序，使我能看到地理上的模式。
____


[quote, 格雷格·艾许(Gregor Aisch), 开放知识基金会]
____
我是Python的超级粉丝。 Python是一种奇妙的开源编程语言，它很容易读写（例如，你不必在每行后键入一个分号）。更重要的是Python有一个庞大的用户群，因此对于你需要的一切都有插件（称为包）来实现。

我认为Django是数据记者很少会用到的东西。它是Python的一个网络应用框架，又称作创建大的、数据库驱动的网络应用工具。这对于小型交互式信息图表肯定有些“杀鸡焉用宰牛刀”了。

我也用QGIS，这是一个开源工具包，为需要不时处理地理数据的数据记者提供广泛的地理信息系统功能。如果您需要把地理空间数据从一种格式转换成另一种，那么QGIS就是你需要的。它可以处理几乎每一种地理数据格式（Shapefiles, KML, GeoJSON等）。如果你需要剪切出几个区域，QGIS也可以做到。并且，围绕着QGIS有一个庞大的讨论交流社区，所以你能够在网上找到众多像http://bit.ly/goettingen-tutorial[教程]这样的自学资源。

R主要是作为一种科学可视化工具被创建的。很难找到一种还没有创建到R中的可视化方法或数据分析技术。R本身就是一个世界，是可视化数据分析的圣地“麦加城”。不够完美的一点是你需要（再一次）学习编程语言，因为R都有它自己的语言。但是，一旦你开始了在学习曲线上的攀爬，就没有什么工具比R更强大了。经过培训的数据记者可以用R来分析庞大的数据集，跨越Excel的限制（比如，你有一个一百万行的表）。 

R有一点非常不错，那就是对于处理数据的全过程，从读取CSV文件到生成表格，你都能够精确地记录下来。如果数据发生变化，可以一键再生成图表。如果有人怀疑图表的完整性，你可以向他展示确切的数据源，让每个人都可以自己生成这张图（或者找到你犯过的错误）。

NumPy + MatPlotLib几乎跟Python的功能是一样的。如果你已经很好地掌握了Python，NumPy + MatPlotLib只是你的一种选择。事实上，NumPy和MatPlotLib是Python程序包的两个例子。它们可以用于数据分析和数据可视化，但都局限于静态的可视化。它们不能被用于制作带有提示工具和高级素材的交互性图表

我不用MapBox，但我听说如果你想基于OpenStreetMap做较为复杂地图的话，它会是一个强大的工具。例如，它可以自定义地图风格（颜色、标签等等）。同时MapBox搭配一个叫Leaflet软件，基本上是用于绘制地图的一个更高级的JavaScript库，可以让你轻易地在地图供应商之间切换（OSM、MapBox、谷歌地图、必应……）。

RaphaelJS是一个相对低水平的可视化语言，允许你进行基本元素的处理（圆、线、文本），并把它们做成动画、进行交互等等。RaphaelJS里没有现成的图表，如柱状图，你得自己画。

但是，Raphael的优点是你做的一切都能在IE浏览器上正常运转。但其他很多的（令人赞叹的）可视化库，像d3，就都不支持IE了。悲剧的是很多用户仍用IE，但没有哪个编辑部能无视占据它们30%的用户需求。

除了RaphaelJS，也其它可以给制作IE 版本Flash的工具替代品。《纽约时报》目前就在做这件事情。这意味着你得把每个应用开发两次。

我始终不认为存在为IE和主流浏览器做可视化的所谓``最好''的工具。我经常发现Raphael在IE上跑得巨慢，几乎比在主流的浏览器中跑Flash慢上十倍。所以如果你想给所有的用户提供高质量的动画可视化，Flash替代版本也许是一个更好的选择。
____

[quote, 史蒂夫·多伊格(Steve Doig), 沃尔特·克朗凯特新闻学院, 亚利桑那州立大学]
____
我用的工具是Excel，它可以处理大部分CAR（计算机辅助报道）问题，并具有简单易学、大多数记者可快速掌握的优点。当需要合并表时，我通常使用Access，但会把合并后的表导出到Excel，做进一步的工作。我使用ESRI的ArcMap做地理分析，它很强大并且被收集地理编码数据的机构所使用。 TextWrangler在快速分析文本数据的布局及分隔方面很强大，并能用规则的表达式进行复杂的搜索和替换。当需要如线性回归这样的统计技术时，我用SPSS，它有一个友好的操作菜单。对于确实繁重的工作，比如处理数百万计的记录、需要认真筛选和程序化变量转换的数据集，我用SAS软件。
____

[quote, 布莱恩·博耶(Brian Boyer), 芝加哥论坛报]
____
我们选择的工具包括Python和Django，用于破解、抓取和操控数据；PostGIS，QGIS和MapBox工具箱，用于建设复杂的网络地图。 我们正在考虑选择R语言还是NumPy+ MatPlotLib做探索性数据分析的工具，虽然目前我们最喜欢的数据工具是自主研发的CSVKit。我们所做的一切或多或少都是在云端部署的。
____

[quote, 安赫利卡·佩拉塔·拉莫斯(Angélica Peralta Ramos), 国家报 (阿根廷)]
____
在《国家报》，我们使用：

*Excel去清洗、组织和分析数据；

*谷歌电子表格去发布、连接像谷歌Fusion Tables、Junar开放数据平台这样的服务；

*Junar用于分享我们的数据，并嵌入我们的文章和博客里；

*Tableau用于发布我们的交互式数据的可视化；

*Qlikview，一个非常快速的商业智能工具，我们用它来分析、筛选大型数据集；

*NitroPDF用来把PDF文件转换成文档和Excel文件；

*谷歌Fusion Tables用于地图可视化。

____

[quote, Pedro Markun, Transparência Hacker]
____
作为一个没有任何技术偏见的草根社区，我们“领军黑客”(Transparência Hacker)使用了很多不同的工具和编程语言。每一个成员都有他一套自己的喜好，这种巨大的差异性既是我们的长处也是我们的弱点。其实我们正在建设一个“透明黑客Linux发行版”，我们可以在任何地方live-boot，并随时进行数据破解。该工具包有一些有趣的工具，比如说Refine，RStudio和OpenOffice Calc（它是个被“聪明人”忽视的工具，但是在快速处理小型数据时确实非常有用）。此外，我们还使用了很多Scraperwiki快速制作原型和在线保存数据和结果。

对于数据可视化及作图，有很多我们喜欢使用的工具。Python和NumPy是很强大的。论坛里有人一直在用R语言，但归根结底我仍然认为Javascript绘图库，如d3,、Flot 和 Raphael，更为大部分项目所使用。最后，我们在绘制地图上进行了许多尝试，而Tilemill确实是一个有趣的工具。
____

=== 使用数据可视化洞察数据

[quote, 威廉·克利夫兰(William S. Cleveland), (Visualizing Data一书作者，Hobart 出版社)]
____
可视化对数据分析至关重要。它是进行数据分析的第一个战场，可以揭示出数据内在的错综复杂的关系，在这一点上可视化的优势是其它方法无可比拟。“我们寻找意想不到的发现，我们挑战料想之中的观点。”
____

数据本身是不可见的，它们以比特和字节的形式存储在计算机硬盘驱动器的某个文件里。为了能让数据的意义得以体现，我们需要将其进行可视化。在这一章里，我将采用广义的_可视化_概念，包括用纯文本展示的数据。例如，把一个数据集加载到某个电子表格软件里，这一过程就可以被认为是数据的可视化。看不见的数据瞬间就变成了屏幕上看得见的“图像”。因此，我们要探讨的问题不是新闻记者需不需要对数据进行可视化处理，而是在何种情况下用何种可视化方法，能够让数据分析达到最佳的效果。

换句话说，什么时候需要采用除表格以外的方式来进行数据的可视化呈现呢?答案很简单：_几乎任何时候_。仅仅使用表格肯定不足以让我们得到对数据集的整体把握。而且，光用表格也不能帮我们直接识别出数据的内在模式。一个最常见的例子就是，与地理位置相关的这一类型的数据，只有当数据在地图上被可视化之后，其具有的特点才能显现出来。然而，除此之外，还有很多其他的模式，我们将在本章的后面看到。

==== 利用可视化进行数据发掘

想要通过可视化工具和技术从数据集中找到一大堆的现成新闻报道，这种想法是不现实的。在数据可视化分析中，没有任何的技术或方法，可以保证你一定能找到数据背后隐藏的故事。相反，通过对数据进行挖掘，洞察数据背后隐藏的秘密对新闻记者来说反而更有用。借此，优秀的新闻记者会将这些数据和洞察巧妙的编织到新闻报道当中。

每一种新的可视化方法都可能会为我们揭示数据的一些新的意义。在这其中，某些可能已经被人们所熟知（但是，可能尚未被证实）；而某些又可能是闻所未闻，甚至让人大吃一惊；一些新的洞见可能会开启一个新闻报道；而其他的可能仅仅是错误数据的结果，所有这些都很可能通过数据可视化来发现。

下面的流程<<FIG054>>对于更有效的进行数据挖掘很有效：

[[FIG054]]
.数据洞察：可视化 (格雷格·艾许)
image::figs/incoming/05-BB.png[float="none"]

===== 学习如何进行数据可视化

可视化为数据集提供了一个独特的视角，进行数据可视化的方法有很多种。

对于处理相对简单的维度的数据，表格的功能是非常强大的。表格可以以最为结构化和组织化的方式显示数据标签和数量，而且结合排序和筛选可以让其功能得到最大程度的发挥。此外，爱德华·塔夫特(Edward Tufte)建议在表格中添加一些小的数据图，例如在每一行加一个柱状图，或者画一个小的线形图（后来也被称为迷你图）。但是，正如在简介中所提到的，表格无疑有其局限性。表格可以轻松帮你找到一维数据的异常值，比如排名前10的数据；但当要同时比较多维数据时（例如每个国家的人口随时间的变化），用表格就力不从心了。

[[FIG055]]
.塔夫特的小贴士：迷你图（格雷格·艾许）
image::figs/incoming/05-BC-graphical-table.png[float="none"]

一般来说，数据图可以让你把数据的不同维度通过几何形状表现出来。关于每种视觉效果的功能可以说上很多，但简单来说就是：颜色不太好用，位置决定一切。比如，在散点图中，数据的两个维度映射到散点图的x轴和y轴。通过改变图标的颜色或大小，你还可以显示出第三个维度的数据。线形图特别适用于显示数据随时间的演变，而柱形图可以很好的用来比较分类数据。你还可以把图表元素相互堆在一起。如果你想比较少数几个组别的数据，那么，用同一类型数据图表示多个实例是一种强大的方法（也称为网格图）。在各种数据图中，你可以使用不同的刻度去发掘数据不同方面的信息（例如使用线性或对数刻度）。

事实上，我们处理的大多数据，都以某种方式与现实大众有所联系。地图的作用就是重新建立数据与我们的物理世界之间的联系。想象一个犯罪事件的地理分布数据集，这其中你最想知道的就是犯罪发生的_地点_，而数据地图可以揭示数据中地理位置的关系，例如从北部到南部，或者从城市到农村地区的趋势。

[[FIG056]]
.等值区域地图（格雷格·艾许）
image::figs/incoming/05-BD-choropleth.png[float="none"]

说到关联，第四种最重要的可视化类型就是网络图谱。网络图谱的功能就是显示数据点（节点）之间的相互联系（边）。节点的位置可以通过简单或复杂的图形布局算法计算得到，使我们能够直观的看到网络内部的结构。一般来说，使用网络图谱进行可视化时，需要注意的是要找到一种合适的方式来对网络本身进行建模。并不是所有的数据集都包含内在联系，即使有，可能也不是数据最有意思的地方。某些时候，节点之间的联系是由新闻记者来定义的。一个完美的例子就是http://slate.me/senate-social[美国参议院的社交网络图]，网络的边用于连接相同投票超过65％的参议员。

===== 对结果进行分析和解释

对数据进行了可视化之后，下一步就是要研究你所创建的数据图。你可以这样问自己：

  * 我可以从这幅图片里看出什么？这是我想要的吗？ 
  * 有什么有趣的模式？ 
  * 在其语境中，它有什么意义？

有的时候，你最后可能会发现，虽然做出来的图非常漂亮，但好像不能提供给你任何有趣的东西。不过，即使没什么价值，你都能够从可视化结果中发现_一些东西_。

===== 记录你的分析步骤和洞察结果

如果把可视化分析看作一段在数据集中的旅程，那么对数据分析过程的记录就是你的旅行日记。它会告诉你到过哪些地方，看见了怎样的景色，以及你如何作出的下一步决定。你甚至可以在看到数据之前，就开始你的记录。

大多数情况下，在开始分析一个未曾见过的数据集之前，我们的头脑中就已经充满了关于它的预想和假设。我们对手头的数据集感兴趣，通常是有原因的。记录下最初的想法是个聪明的做法。通过对预想的记录可以可以帮助我们识别偏见，降低误读的风险。

我坚持认为记录是这个流程中最重要的一步，而它也是我们最容易忽略跳过的一步。在下面你将要看到的例子中，我所描述的流程中涉及了大量的作图和数据加工。看着一组15张你做的图，你可能会摸不着头脑，特别是经过一段时间之后。实际上，这些图只有呈现在其产生的语境中才是有价值的（对你或其他你想要与之分享你的发现的人）。因此，你应该花时间做些这样的笔记：

  * 我为什么要做这个图？ 
  * 为了做这张图，我对数据做了哪些处理？
  * 这张图想表达什么意思？ 

===== 转换数据

自然地，带着从上一步可视化处理中收获的洞察，你可能对下一步想看到什么有了想法。可能你已经在数据集中发现了一些有趣的模式，那么，现在你想要对其进行更细致的分析。

可以进行的数据转换包括：

缩放::
  能够看可视化图中某一特定部分的细节
汇总::
  将多个数据点合并到一个组
过滤::
  （暂时性的）移除不是主要关注对象的数据点。 
去除异常值::
  排除异于99％数据的的单个的数据点。

让我们想象一下你所得到的可视化图表，其中能看到的只是一堆杂乱无章的点和成百上千的连线（在可视化所谓的密集连接网络中经常出现这种情况），一个常用的转换步骤是过滤掉某些连线。例如，如果一些边代表捐助国向受援国方向的资金流动，我们可以去掉低于某一金额的资金流动的数据。

==== 使用什么工具

选择恰当的数据可视化工具并不是一件容易的事。每一种数据可视化工具都有其擅长的地方。可视化和数据加工应当是简单和高效的。如果你需要几个小时来调整参数，你就不会作出太多的尝试。这并不是说你不需要学习如何使用工具。不过一旦你学会了，它就应该是非常高效的。

通常，选择一个可以兼顾数据加工和数据可视化的工具是很有必要的。把任务分散在不同的工具中意味着你不得不把数据导来导去。下面简短列出了一些数据可视化和数据处理的工具：

  * 电子表格，如LibreOffice、Excel或Google文档。
  * 统计编程架构，如R（r-project.org）或Pandas（pandas.pydata.org） 
  * 地理信息系统（GIS），如Quantum GIS、ArcGIS和GRASS
  * 可视化程序包，如d3.js（mbostock.github.com/d3）、Prefuse（prefuse.org）和Flare（flare.prefuse.org） 
  * 数据加工工具，如Google Refine、Datawrangler 
  * 非编程可视化软件，如ManyEyes和Tableau Public（tableausoftware.com/products/public）

下一节中的可视化实例就是用R语言创建的，它是（科学）数据可视化的利器。

==== 可视化实例：感知美国总统大选捐款数据

让我们来看看美国总统竞选财务数据库，其中包含约45万笔捐给各个总统候选人的款项。 这份数据保存在60兆大小的一个CSV文件里，用Excel这样的程序处理这么大的数据是非常吃力的。

首先，我会明确地写下对联邦选举委员会捐款数据的初步猜测：

  * 奥巴马应该会得到最多的捐款，（因为他是现任总统且人气最高）。 
  * 随着选举日临近，捐款数目增加。
  * 奥巴马比共和党候选人获得更多的小额捐款。 

要回答第一个问题，需要对数据做些_转换_。我们不能只看每笔单独的捐款，而需要把每位候选人收到的捐款总金额算出来。在用分类汇总表对结果进行_可视化_后，可以确认我们的假设是正确的，奥巴马确实收到了最多的捐款：

[options="header"]
|=======================
|候选人 | 金额 ($)
|奥巴马, 巴拉克 | 72,453,620.39
|罗姆尼, 米特 | 50,372,334.87
|佩里, 里特 | 18,529,490.47
|保罗, 荣恩 | 11,844,361.96
|凯恩, 赫尔曼 | 7,010,445.99
|金里奇, 纽特 | 6,311,193.03
|波伦提, 提摩西 | 4,202,769.03
|亨斯迈, 乔恩 | 2,955,726.98
|巴赫曼, 米歇尔 | 2,607,916.06
|桑托伦, 里特 | 1,413,552.45
|约翰逊, 加里·厄尔 | 413,276.89
|罗默，查尔斯·E·布迪三世 | 291,218.80
|麦克寇特，赛迪斯 | 37,030.00
|=======================

虽然从这个表能看出候选人收到捐款的最大值、最小值和排序情况，但它并没有揭示候选人排名的潜在模式。<<FIG059>>是这份数据的另一种可视化，被称为“点状图”，从中我们可以看出表格所呈现的所有信息，以及数据的内在模式。例如，在点状图里我们不需要做减法运算，就可以直接比较奥巴马与罗姆尼或者罗姆尼与佩里之间的差距。（注：这张图由R语言创建，你可以在本章末尾找到源代码的链接）。

[[FIG059]]
.用散点将潜在的模式可视化（格雷格·艾许）
image::figs/incoming/05-CC.png[float="0"]

现在，让我们接着做一张更大的图。首先，我用一个简单的散点图_显示_捐款金额随时间的变化情况。可以看到，有三个巨大的离群值，跟它相比其他捐款都微乎其微。进一步调查发现，这些巨额捐款都来自``奥巴马胜利基金2012''（又名超级PAC），该基金分别在去年6月29日捐款45万美元， 9月29日捐款150万美元， 12月30日捐款190万美元。

[[FIG0510]]
.三个明显离群值（格雷格·艾许）
image::figs/incoming/05-DD.png[float="none"]

超级PAC(政治行动委员会)的巨额捐款无疑是这一数据最大的发现，但除此以外可能还有其他有意思的地方。现在的问题是，这些巨额捐款会影响我们对来自个人的小额捐款的分析，所以要把它们从数据中剔除出去。这种转换通常称为去除离群值。再次进行可视化，可以看到，大多数捐款都在5千到1万美元的范围内。

[[FIG0511]]
.删除离群值（格雷格·艾许）
image::figs/incoming/05-EE.png[float="none"]

根据联邦竞选法对个人捐款所设置的限制，每位候选人不允许接受超过2500美元的个人捐款。但我们从图中看到，很多捐款都超出了这一限额。特别是五月的两笔大额捐款引起了我们的注意。它们看起来与六月和七月的负数金额（退款）相对应。进一步的数据调查，发现了以下交易：

  * 受聘于班纳克事务所（律师）来自旧金山的_斯蒂芬·詹姆斯·戴维斯_，在5月10日向奥巴马捐款*$25,800*。 
  * 受聘于墨菲集团（公共关系）来自小石城的_辛西娅·墨菲_，在5月25日奥巴马捐款*$33,300*。
  * 6月15日，*$30,800*被退还给_辛西娅·墨菲_，其中扣除了*$2500*的捐款。
  * 7月8日，*$25,800*被退还给斯蒂芬·詹姆斯·戴维斯，其中并没有扣除任何捐款。 

这些数字有什么特别的意义吗？退还给辛西娅·墨菲的30,800美元，等于每年个人向全国各政党委员会捐款的最高金额。或许她只是想把给总统选举的钱和给民主党的一次捐了，但最后被拒了。而退还斯蒂芬·詹姆斯·戴维斯的25,800美元等于30,800减去5000美元，而5000美元是个人向其他政党委员会捐款的限额。

上一张图里另一个有趣的发现，就是可以看到向共和党候选人的捐款分别在5000美元和-2500美元有一条水平线。为了看得更清楚，我单独把共和党的捐款可视化。如果不进行可视化，是不可能发现这些内在的模式的，这里做出来的数据图也是对此最好的佐证。这些图是数据内在模式的完美实例，没有数据可视化，它们是不可能被发现的。

[[FIG0512]]
.删除离群值2（格雷格·艾许）
image::figs/incoming/05-FF.png[float="none"]

我们可以看到，向共和党候选人捐款的数值主要集中在5000美元，但实际去看一下数据你会发现，这样的捐款有1243笔，只占捐款总笔数的有0.3％，但因为其他的捐款数额随时间分布比较均匀，所以在这里才能看出这条线。有意思的是，个人的捐款限额是2500美元。因此，超过额度的捐款会退还给捐助者，这就是为什么在-2500美元的位置出现了第二条线。相反，对奥巴马的捐助没有呈现类似的情况。

[[FIG0513]]
.删除离群值2（格雷格·艾许）
image::figs/incoming/05-GG.png[scale="86",float="none"]

接下来，就来看看为什么数以千计的共和党捐助者都没注意到个人捐款限额这件事。可能会非常有趣。为了进一步分析这个议题，我们看看各位候选人获得的5000美元捐款的总笔数。

[[FIG0514]]
.每个候选人获得的捐款（格雷格·艾许）
image::figs/incoming/05-HH.png[scale="86",float="none"]

当然，这是一幅被曲解的图因为它没有考虑各候选人收到的捐款总额。下图显示每位侯选人收到的超过5000美元的捐款在总捐款笔数中的比例。

[[FIG0515]]
.参议员的钱从何而来？每个候选人的捐款（格雷格·艾许）
image::figs/incoming/05-II.png[scale="88",float="none"]

==== 我们能从中学到什么

这样一个对未知数据集进行可视化分析的过程，常常让人感觉像在一个陌生的国度进行一次令人兴奋的旅行。你凭借仅有的数据和一些假想，就像一个外国人一样开始，，但每进行一步，每做出一张图表，你都会获得有关这个议题的新的洞察。基于这些洞察，你再确定下一步的分析方向，以及数据的哪些方面值得去深入研究。正如你在这一章所看到的，这种数据可视化、分析以及转换的过程几乎可以无限重复下去。

==== 获得源代码

本章中的所有图表都是通过美妙而强大的R语言绘制的。R语言主要用作科学的可视化工具，它几乎可以实现任何已有的可视化或者数据加工方法。如果你对利用R来进行可视化或数据加工感兴趣，下面是绘制本章图表所用的源代码。此外，还有种类繁多的书籍和教程可供选择。
dotch


  *https://gist.github.com/1769733[点状图：每个候选人得到的选款]
  *https://gist.github.com/1816161[散点图：捐款随时间的变化]
  *https://gist.github.com/1816169[散点图：授权委员会的捐款]

还有种类繁多的书籍和教程可供选择。

&mdash; _格雷格·艾许(Gregor Aisch)，开放知识基金会_
